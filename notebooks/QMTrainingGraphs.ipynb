{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG2gZSoSJD5C"
      },
      "source": [
        "# Quanta Maths: Integer Addition and Subtraction in Transformers - Training Graphs\n",
        "\n",
        "This Colab graphs training data across multiple models.\n",
        "\n",
        "This Colab follows on from https://github.com/PhilipQuirke/quanta_maths/blob/main/notebooks/QMTrain.ipynb which trained the models, and outputs model.pth and training_loss.json\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzkGrSqHJKqN"
      },
      "source": [
        "## Tips for using the Colab\n",
        " * You can run and alter the code in this CoLab notebook yourself in Google CoLab ( https://colab.research.google.com/ ).\n",
        " * To run the notebook, in Google CoLab, **you will need to** go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.\n",
        " * Some graphs are interactive!\n",
        " * Use the table of contents pane in the sidebar to navigate.\n",
        " * Collapse irrelevant sections with the dropdown arrows.\n",
        " * Search the page using the search in the sidebar, not CTRL+F."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTd3nmsMJV5T"
      },
      "source": [
        "# Part 0: Import libraries\n",
        "Imports standard libraries.\n",
        "\n",
        "Imports \"MathsQuanta\" public library as \"mmi\". Refer to [README.md](https://github.com/PhilipQuirke/Quanta_Maths/blob/main/README.md) for more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCdmr6-_Jkzi"
      },
      "outputs": [],
      "source": [
        "DEVELOPMENT_MODE = True\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        " \n",
        "    !pip install matplotlib\n",
        "    !pip install kaleido\n",
        "\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    #!pip install matplotlib==3.8.4\n",
        "    #!pip install kaleido==0.2.1\n",
        "    # Install required libraries if not already installed\n",
        "    import sys\n",
        "    import subprocess\n",
        "    def install(package):\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "    # List of required packages\n",
        "    required_packages = [\"matplotlib\", \"kaleido\", \"plotly\", \"nbformat\", \"scikit-learn\", \"scikit-optimize\", \"huggingface_hub\", \"torch\", \"numpy\"]\n",
        "    for pkg in required_packages:\n",
        "        try:\n",
        "            __import__(pkg.replace('-', '_'))\n",
        "        except ImportError:\n",
        "            print(f\"Installing {pkg}...\")\n",
        "            install(pkg)\n",
        "\n",
        "    from IPython import get_ipython\n",
        "    ipython = get_ipython()\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2\n",
        "\n",
        "    # Uncomment below to force reinstall if needed\n",
        "    # for pkg in required_packages:\n",
        "    #     install(pkg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jx90-d4w23jk"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import QuantaMechInterp as qmi\n",
        "except ImportError:\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install --upgrade git+https://github.com/PhilipQuirke/quanta_mech_interp.git\n",
        "    import QuantaMechInterp as qmi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bjUhEHa-AgQ"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import MathsMechInterp as mmi\n",
        "except ImportError:\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install --upgrade git+https://github.com/PhilipQuirke/quanta_maths.git\n",
        "    import MathsMechInterp as mmi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Up2QLAZLJnG9"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import kaleido\n",
        "import plotly.io as pio\n",
        "\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve-TndERJoaJ"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6zOEFryJqGN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6TE7A9SxySA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOh-m1lO4hrO"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import sklearn # Aka scikit.learn\n",
        "import skopt # Aka scikit.optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8VQ4e0QJsIB"
      },
      "outputs": [],
      "source": [
        "import transformer_lens\n",
        "from transformer_lens.utils import download_file_from_hf\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldGPkaokJQM5"
      },
      "source": [
        "# Part 1A: Configuration\n",
        "\n",
        "Which existing model do we want to graph?\n",
        "\n",
        "The existing model weightings created by the sister Colab [QuantaMathsTrain](https://github.com/PhilipQuirke/Quanta_Maths/blob/main/assets/QuantaMathsTrain.ipynb) are loaded from HuggingFace (in Part 5). Refer https://github.com/PhilipQuirke/quanta_maths/blob/main/README.md for more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1DXZQ2E6yAi"
      },
      "outputs": [],
      "source": [
        "# Singleton QuantaTool \"main\" configuration class. MathsConfig is derived from the chain AlgoConfig > UsefulConfig > ModelConfig\n",
        "cfg = mmi.MathsConfig()\n",
        "\n",
        "\n",
        "# Which model do we want to graph? Uncomment one line:\n",
        "\n",
        "# Addition models\n",
        "#cfg.set_model_names( \"add_d5_l1_h3_t15K_s372001\" )  # AddAccuracy=Two9s. Inaccurate as only has one layer. Can predict S0, S1 and S2 complexity questions.\n",
        "#cfg.set_model_names( \"add_d5_l2_h3_t15K_s372001\" )  # AddAccuracy=Six9s. AvgFinalLoss=1.6e-08\n",
        "#cfg.set_model_names( \"add_d5_l2_h3_t40K_s372001\" )  # AddAccuracy=Six9s. AvgFinalLoss=2e-09. Fewest nodes\n",
        "#cfg.set_model_names( \"add_d6_l2_h3_t15K_s372001\" )  # AddAccuracy=Fives. AvgFinalLoss=1.7e-08. (2/M fail: 018539+789353=+0807892 ModelAnswer: +0707892, 747332+057349=+0804681 ModelAnswer: +0704681)\n",
        "#cfg.set_model_names( \"add_d6_l2_h3_t20K_s173289\" )  # AddAccuracy=Six9s. AvgFinalLoss=1.5e-08. Fewest nodes\n",
        "#cfg.set_model_names( \"add_d6_l2_h3_t20K_s572091\" )  # AddAccuracy=Six9s. AvgFinalLoss=7e-09\n",
        "#cfg.set_model_names( \"add_d6_l2_h3_t40K_s372001\" )  # AddAccuracy=Six9s. AvgFinalLoss=2e-09\n",
        "#cfg.set_model_names( \"add_d7_l2_h3_t45K_s173289\" )  # AddAccuracy=Six9s. AvgFinalLoss=3e-09. (0/M fail)\n",
        "#cfg.set_model_names( \"add_d8_l2_h3_t45K_s173289\" )  # AddAccuracy=Six9s. AvgFinalLoss=3e-09. (0/M fail)\n",
        "#cfg.set_model_names( \"add_d9_l2_h3_t45K_s173289\" )  # AddAccuracy=Six9s. AvgFinalLoss=3e-09. (0/M fail)\n",
        "#cfg.set_model_names( \"add_d10_l2_h3_t40K_s572091\" ) # AddAccuracy=Six9s. AvgFinalLoss=7e-09. (1/M fail: 0000000555+0000000445=+00000001000 ModelAnswer: +00000000900)\n",
        "#cfg.set_model_names( \"add_d10_l2_h3_t40K_gf_s572091\" ) # AddAccuracy=Six9s. AvgFinalLoss=3.5-09. GrokFast.\n",
        "#cfg.set_model_names( \"add_d11_l2_h3_t50K_s572091\" )  # AddAccuracy=Five9s. AvgFinalLoss=8e-09. (2/M fail)\n",
        "#cfg.set_model_names( \"add_d12_l2_h3_t50K_s572091\" )  # AddAccuracy=Five9s. AvgFinalLoss=5e-09. (3/M fail)\n",
        "#cfg.set_model_names( \"add_d13_l2_h3_t50K_s572091\" )  # AddAccuracy=Six9s. AvgFinalLoss=6.3e-08. (1/M fail)\n",
        "cfg.set_model_names( \"add_d14_l2_h3_t60K_s572091\" )  # AddAccuracy=Three9S. AvgFinalLoss=5.6e-06. (199/M fail)\n",
        "#cfg.set_model_names( \"add_d15_l2_h3_t80K_s572091\" ) # AddAccuracy=Five9s. AvgFinalLoss=8.6e-08 (10/M fail)\n",
        "#cfg.set_model_names( \"add_d20_l2_h3_t80K_s572091\" ) # AddAccuracy=Poor! AvgFinalLoss=0.20!\n",
        "\n",
        "# Subtraction model\n",
        "#cfg.set_model_names( \"sub_d6_l2_h3_t30K_s372001\" )  # SubAccuracy=Six9s. AvgFinalLoss=5.8e-06\n",
        "#cfg.set_model_names( \"sub_d10_l2_h3_t75K_s173289\" )  # SubAccuracy=Two9s. (6672/M fails) AvgFinalLoss=0.002002.\n",
        "#cfg.set_model_names( \"sub_d10_l2_h3_t75K_gf_s173289\" )  # SubAccuracy=Two9s. GrokFast. (5246/M fails) AvgFinalLoss=0.001197\n",
        "\n",
        "# Mixed (addition and subtraction) model\n",
        "#cfg.set_model_names( \"mix_d5_l3_h4_t40K_s372001\" )  # Add/SubAccuracy=Six9s/Six9s. AvgFinalLoss=9e-09. (0/M fails, 0/M fails)\n",
        "#cfg.set_model_names( \"mix_d6_l3_h4_t40K_s372001\" )  # Add/SubAccuracy=Six9s/Six9s. AvgFinalLoss=5e-09. (1/M fail)\n",
        "#cfg.set_model_names( \"mix_d7_l3_h4_t50K_s372001\" )  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss=2e-08. (2/M fails, 6/M fails)\n",
        "#cfg.set_model_names( \"mix_d8_l3_h4_t60K_s173289\" )  # Add/SubAccuracy=Six9s/Five9s. AvgFinalLoss=4.7e-08. (0/M fails, 7/M fails)\n",
        "#cfg.set_model_names( \"mix_d9_l3_h4_t60K_s173289\" )  # Add/SubAccuracy=Six9s/Four9s. AvgFinalLoss=3.2e-07. (1/M fails, 33/M fails)\n",
        "#cfg.set_model_names( \"mix_d10_l3_h4_t75K_s173289\" )  # Add/SubAccuracy=Five9s/Two9s. AvgFinalLoss=1.125e-06 (2/M fail, 295/M fail)\n",
        "#cfg.set_model_names( \"mix_d10_l3_h4_t75K_gf_s173289\" )  # Add/SubAccuracy=Six9s/Three9s. GrokFast. AvgFinalLoss=8.85e-07 (1/M fail, 294/M fail)\n",
        "#cfg.set_model_names( \"mix_d11_l3_h4_t80K_s572091\" )  # Add/SubAccuracy=Six9s/Four9s AvgFinalLoss=3.9e-08 (0/M fail, 13/M fail)\n",
        "#cfg.set_model_names( \"mix_d12_l3_h4_t85K_s572091\" )  # Add/SubAccuracy=TODO\n",
        "#cfg.set_model_names( \"mix_d13_l3_h4_t85K_s572091\" )  # Add/SubAccuracy=TODO\n",
        "\n",
        "# Mixed models initialized with addition model\n",
        "#cfg.set_model_names( \"ins1_mix_d5_l2_h3_t40K_s572091\" )  # Add/SubAccuracy=TODO\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l2_h3_t40K_s572091\" )  # Add/SubAccuracy=Six9s/Five9s. AvgLoss = 2.4e-08 (5/M fails)\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l3_h3_t40K_s572091\" )  # Add/SubAccuracy=Six9s/Five9s. AvgFinalLoss=1.8e-08. (3/M fails)\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l3_h3_t80K_s572091\" )  # Add/SubAccuracy=Six9s/Five9s AvgLoss = 1.6e-08 (3/M fails)\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l3_h4_t40K_s372001\" )  # Add/SubAccuracy=Six9s/Six9s. AvgFinalLoss=8e-09. MAIN FOCUS\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l3_h4_t40K_s173289\" )  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss=1.4e-08. (3/M fails, 2/M fails)\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l3_h4_t50K_s572091\" )  # Add/SubAccuracy=Six9s/Five9s. AvgFinalLoss=2.9e-08. (4/M fails)\n",
        "#cfg.set_model_names( \"ins1_mix_d7_l3_h4_t50K_s572091\" )  # Add/SubAccuracy=TODO\n",
        "#cfg.set_model_names( \"ins1_mix_d8_l3_h4_t70K_s572091\" )  # Add/SubAccuracy=TODO\n",
        "#cfg.set_model_names( \"ins1_mix_d9_l3_h4_t70K_s572091\" )  # Add/SubAccuracy=TODO\n",
        "#cfg.set_model_names( \"ins1_mix_d10_l3_h3_t50K_s572091\" )  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss 6.3e-07 (6/M fails, 7/M fails)\n",
        "#cfg.set_model_names( \"ins1_mix_d10_l3_h3_t50K_gf_s572091\" ) # Add/SubAccuracy=Five9s/Two9s. GrokFast. AvgFinalLoss=4.0e-06 (2/M fails, 1196/M fails)\n",
        "#cfg.set_model_names( \"ins1_mix_d11_l3_h4_t75K_s572091\" )  # Add/SubAccuracy=TODO\n",
        "\n",
        "# Mixed model initialized with addition model. Reset useful heads every 100 epochs.\n",
        "#cfg.set_model_names( \"ins2_mix_d6_l4_h4_t40K_s372001\" )  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss=1.7e-08. (3/M fails e.g. 530757+460849=+0991606 ModelAnswer: +0091606) (8 fails e.g. 261926-161857=+0100069 ModelAnswer: +0000069)\n",
        "\n",
        "# Mixed model initialized with addition model. Reset useful heads & MLPs every 100 epochs.\n",
        "#cfg.set_model_names( \"ins3_mix_d6_l4_h3_t40K_s372001\" )  # Add/SubAccuracy=Four9s/Two9s. AvgFinalLoss=3.0e-04. (17/M fails e.g. 273257+056745=+0330002 ModelAnswer: +0320002) (3120 fails e,g. 09075-212133=-0003058 ModelAnswer: +0003058)\n",
        "\n",
        "# Addition&Subtraction model initialized with addition model. Reset useful heads & MLPs every epoch\n",
        "#cfg.set_model_names( \"ins4_mix_d6_l4_h3_t40K_s372001\" )  # AvgFinalLoss 4.7e-06\n",
        "\n",
        "# Mixed models initialized with addition model. Insert mode 5\n",
        "#cfg.set_model_names( \"ins5_mix_d6_l3_h4_t30K_s775824\" )  # Add/SubAccuracy=???/??? TODO\n",
        "#cfg.set_model_names( \"ins5_mix_d6_l2_h4_t30K_s775824\" )  # Add/SubAccuracy=???/??? TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_IIpX2H2tNe"
      },
      "source": [
        "# Part 1B: Configuration: Input and Output file names\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0DJkn5l2gq3"
      },
      "outputs": [],
      "source": [
        "base_repo_name = 'PhilipQuirke'\n",
        "model_pth_fname = 'model.pth'\n",
        "model_training_loss_fname = 'training_loss.json'\n",
        "model_behaviors_fname = 'behaviors.json'\n",
        "model_features_fname = 'features.json'\n",
        "\n",
        "cfg.hf_repo = base_repo_name + \"/QuantaMaths_\" + cfg.model_name\n",
        "\n",
        "print('Model files will be read from HuggingFace repo:', base_repo_name, model_pth_fname, 'and', model_training_loss_fname)\n",
        "print('Model analysis tags will be read from HuggingFace repo:', model_behaviors_fname, 'and', model_features_fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfdCBTuqh4zq"
      },
      "outputs": [],
      "source": [
        "# Update \"cfg\" with additional training config (including cfg.insert_*) with information stored in:\n",
        "#      https://huggingface.co/.../QuantaMaths_ins1_mix_d6_l3_h4_t40K_s372001/training_loss.json\"\n",
        "training_data_json = qmi.download_huggingface_json(cfg.hf_repo, model_training_loss_fname)\n",
        "training_loss_list = qmi.load_training_json(cfg, training_data_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keTceF_3zbVP"
      },
      "source": [
        "# Part 2: Single model training loss graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCwcStUps62W"
      },
      "outputs": [],
      "source": [
        "print(\"%Add=\", cfg.perc_add, \"%Sub=\", cfg.perc_sub, \"%Mult=\", cfg.perc_mult, \"InsertMode=\", cfg.insert_mode, \"File=\", cfg.model_name)\n",
        "print(\"weight_decay=\", cfg.weight_decay, \"lr=\", cfg.lr, \"batch_size=\", cfg.batch_size)\n",
        "print( \"Avg loss over last 5 epochs (AvgFinalLoss)\", cfg.avg_final_loss)\n",
        "print( \"Final epoch loss\", cfg.final_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYV9FWt3zfFw"
      },
      "outputs": [],
      "source": [
        "# Show the model final training loss and graph loss over epochs\n",
        "if training_loss_list:\n",
        "  answer_digits = cfg.n_digits + 1\n",
        "  title_font_size=32\n",
        "  tick_font_size=24\n",
        "\n",
        "  qmi.plot_loss_lines(cfg, 1500, [training_loss_list[:1500]], labels = ['All'], log_y=False,\n",
        "                       title='Training Loss', title_font_size=title_font_size, tick_font_size=tick_font_size)\n",
        "\n",
        "  full_title, fig = qmi.plot_loss_lines(cfg, cfg.n_training_steps, [training_loss_list], labels = ['All'], log_y=True,\n",
        "                       title='Training Loss', title_font_size=title_font_size, tick_font_size=tick_font_size)\n",
        "  pio.write_image(fig, cfg.model_name + '_LogTrainingLoss.' + cfg.graph_file_suffix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sWq2xyVUzOJ"
      },
      "source": [
        "# Part 3A: Multiple model training loss graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyDE-E3LCo6O"
      },
      "outputs": [],
      "source": [
        "all_training_loss_lists = []\n",
        "model_labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeoJEIkv-JPd"
      },
      "outputs": [],
      "source": [
        "# Load and process the training loss data from each model\n",
        "def load_training_data(model_names):\n",
        "  global all_training_loss_lists\n",
        "  global model_labels\n",
        "\n",
        "  all_training_loss_lists = []\n",
        "  model_labels = []\n",
        "\n",
        "  for model_name in model_names:\n",
        "      the_repo = base_repo_name + \"/QuantaMaths_\" + model_name\n",
        "      training_data_json = qmi.download_huggingface_json(the_repo, model_training_loss_fname)\n",
        "      training_loss_list = qmi.load_training_json(cfg, training_data_json)\n",
        "      all_training_loss_lists.append(training_loss_list)\n",
        "\n",
        "      cfg2 = mmi.MathsConfig()\n",
        "      cfg2.set_model_names( model_name )\n",
        "      model_labels.append( \"d\" + str(cfg2.n_digits))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVq8um7Ehues"
      },
      "outputs": [],
      "source": [
        "def smooth_data(data, window_size=500):\n",
        "    \"\"\"Apply rolling statistics to the data\"\"\"\n",
        "    series = pd.Series(data)\n",
        "    smoothed_mean = series.rolling(window=window_size, center=True).mean()\n",
        "    smoothed_min = series.rolling(window=window_size, center=True).min()\n",
        "    smoothed_max = series.rolling(window=window_size, center=True).max()\n",
        "    return smoothed_mean, smoothed_min, smoothed_max\n",
        "\n",
        "def hex_to_rgba(hex_color, alpha=0.2):\n",
        "    \"\"\"Convert hex color to rgba string with alpha\"\"\"\n",
        "    hex_color = hex_color.lstrip('#')\n",
        "    r = int(hex_color[0:2], 16)\n",
        "    g = int(hex_color[2:4], 16)\n",
        "    b = int(hex_color[4:6], 16)\n",
        "    return f'rgba({r},{g},{b},{alpha})'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QP7tuGeWtam"
      },
      "outputs": [],
      "source": [
        "def plot_training_data_regular(prefix):\n",
        "    global all_training_loss_lists\n",
        "    global model_labels\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Color palette for different traces\n",
        "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',\n",
        "              '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#aec7e8']\n",
        "\n",
        "    for i, loss_list in enumerate(all_training_loss_lists):\n",
        "        # Limit data to first 15K steps to reduce memory usage\n",
        "        max_steps = 15000\n",
        "        loss_list = loss_list[:max_steps]\n",
        "        x_vals = list(range(len(loss_list)))\n",
        "\n",
        "        smooth_mean, smooth_min, smooth_max = smooth_data(loss_list)\n",
        "\n",
        "        # Plot smooth_min first\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=x_vals,\n",
        "                y=smooth_min,\n",
        "                mode='lines',\n",
        "                line=dict(width=0),\n",
        "                hoverinfo='skip',\n",
        "                showlegend=False\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Plot smooth_max with fill='tonexty'\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=x_vals,\n",
        "                y=smooth_max,\n",
        "                mode='lines',\n",
        "                line=dict(width=0),\n",
        "                fillcolor=hex_to_rgba(colors[i]),\n",
        "                fill='tonexty',\n",
        "                hoverinfo='skip',\n",
        "                showlegend=False\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Add mean line\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=x_vals,\n",
        "                y=smooth_mean,\n",
        "                mode='lines',\n",
        "                line=dict(color=colors[i], width=2),\n",
        "                name=model_labels[i]\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title=prefix + \" Training Loss Comparison (First 15K Steps)\",\n",
        "        height=600,\n",
        "        template=\"plotly_white\",\n",
        "        showlegend=True,\n",
        "        legend=dict(\n",
        "            yanchor=\"top\",\n",
        "            y=0.95,\n",
        "            xanchor=\"right\",\n",
        "            x=0.95\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Update axes labels and ranges\n",
        "    fig.update_xaxes(title_text=\"Training Step\", range=[0, max_steps])\n",
        "    fig.update_yaxes(title_text=\"Training Loss\")\n",
        "\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUXfVP91WuIu"
      },
      "outputs": [],
      "source": [
        "def plot_training_data_log(prefix):\n",
        "    global all_training_loss_lists\n",
        "    global model_labels\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Color palette for different traces\n",
        "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',\n",
        "              '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#aec7e8']\n",
        "\n",
        "    for i, loss_list in enumerate(all_training_loss_lists):\n",
        "        # Limit data to 80K steps or the length of the loss_list\n",
        "        max_steps = min(80000, len(loss_list))\n",
        "        loss_list = loss_list[:max_steps]\n",
        "        x_vals = list(range(len(loss_list)))\n",
        "\n",
        "        smooth_mean, smooth_min, smooth_max = smooth_data(loss_list)\n",
        "\n",
        "        # Plot smooth_min first\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=x_vals,\n",
        "                y=smooth_min,\n",
        "                mode='lines',\n",
        "                line=dict(width=0),\n",
        "                hoverinfo='skip',\n",
        "                showlegend=False\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Plot smooth_max with fill='tonexty'\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=x_vals,\n",
        "                y=smooth_max,\n",
        "                mode='lines',\n",
        "                line=dict(width=0),\n",
        "                fillcolor=hex_to_rgba(colors[i]),\n",
        "                fill='tonexty',\n",
        "                hoverinfo='skip',\n",
        "                showlegend=False\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Add mean line\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=x_vals,\n",
        "                y=smooth_mean,\n",
        "                mode='lines',\n",
        "                line=dict(color=colors[i], width=2),\n",
        "                name=model_labels[i]\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title=prefix + \" Training Loss Comparison (Log Scale)\",\n",
        "        height=600,\n",
        "        template=\"plotly_white\",\n",
        "        showlegend=True,\n",
        "        legend=dict(\n",
        "            yanchor=\"top\",\n",
        "            y=0.95,\n",
        "            xanchor=\"right\",\n",
        "            x=0.95\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Update axes labels and ranges\n",
        "    fig.update_xaxes(title_text=\"Training Step\", range=[0, max_steps])\n",
        "    fig.update_yaxes(title_text=\"Training Loss (Log Scale)\", type=\"log\")\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "    qmi.save_plt_to_file(cfg=cfg, full_title=prefix + \"_training\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9LwyWRH994V"
      },
      "source": [
        "# Part 3B: Multiple Addition model training loss graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be50S0Yw99WK"
      },
      "outputs": [],
      "source": [
        "model_names1 = [\n",
        "    \"add_d5_l2_h3_t40K_s372001\",\n",
        "    \"add_d6_l2_h3_t40K_s372001\",\n",
        "    \"add_d7_l2_h3_t45K_s173289\",\n",
        "    \"add_d8_l2_h3_t45K_s173289\",\n",
        "    \"add_d9_l2_h3_t45K_s173289\",\n",
        "    \"add_d10_l2_h3_t40K_s572091\",\n",
        "    \"add_d11_l2_h3_t50K_s572091\",\n",
        "    \"add_d12_l2_h3_t50K_s572091\",\n",
        "    \"add_d13_l2_h3_t50K_s572091\",\n",
        "    \"add_d14_l2_h3_t60K_s572091\",\n",
        "    \"add_d15_l2_h3_t80K_s572091\",\n",
        "]\n",
        "\n",
        "load_training_data(model_names1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDZjTfwBC0QE"
      },
      "outputs": [],
      "source": [
        "#plot_training_data_regular(\"Addition\")\n",
        "plot_training_data_log(\"Addition\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh_Ho4oW-0m9"
      },
      "source": [
        "#Part 3C: Multiple Mixed (Addition and Subtraction) model training loss graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2J9ZaIn--6E"
      },
      "outputs": [],
      "source": [
        "model_names2 = [\n",
        "    \"mix_d5_l3_h4_t40K_s372001\",\n",
        "    \"mix_d6_l3_h4_t40K_s372001\",\n",
        "    \"mix_d7_l3_h4_t50K_s372001\",\n",
        "    \"mix_d8_l3_h4_t60K_s173289\",\n",
        "    \"mix_d9_l3_h4_t60K_s173289\",\n",
        "    \"mix_d10_l3_h4_t75K_s173289\",\n",
        "    \"mix_d11_l3_h4_t80K_s572091\",\n",
        "    \"mix_d12_l3_h4_t85K_s572091\",\n",
        "    \"mix_d13_l3_h4_t85K_s572091\",\n",
        "]\n",
        "\n",
        "load_training_data(model_names2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQfrFLhqW16n"
      },
      "outputs": [],
      "source": [
        "#plot_training_data_regular(\"Mixed\")\n",
        "plot_training_data_log(\"Mixed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1fCjqNL_Qu0"
      },
      "source": [
        "#Part 3D: Multiple Mixed models initialized with addition models training loss graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMEZtKFi_ZOC"
      },
      "outputs": [],
      "source": [
        "model_names3 = [\n",
        "    \"ins1_mix_d5_l2_h3_t40K_s572091\",\n",
        "    \"ins1_mix_d6_l3_h4_t40K_s372001\",\n",
        "    \"ins1_mix_d7_l3_h4_t50K_s572091\",\n",
        "    \"ins1_mix_d8_l3_h4_t70K_s572091\",\n",
        "    \"ins1_mix_d9_l3_h4_t70K_s572091\",\n",
        "    \"ins1_mix_d10_l3_h3_t50K_s572091\",\n",
        "    \"ins1_mix_d11_l3_h4_t75K_s572091\",\n",
        "]\n",
        "\n",
        "load_training_data(model_names3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dJE5npWC7Es"
      },
      "outputs": [],
      "source": [
        "#plot_training_data_regular(\"Inited Mixed\")\n",
        "plot_training_data_log(\"Inited Mixed\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uG2gZSoSJD5C",
        "pTd3nmsMJV5T",
        "keTceF_3zbVP"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
