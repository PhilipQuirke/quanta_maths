{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab604d1a",
   "metadata": {},
   "source": [
    "# Quanta Maths: Integer Addition and Subtraction in Transformers. Scan 200+ LLMs\n",
    "\n",
    "This Colab uses the app.withmartian.com API to test 200+ models\n",
    "to see whether given query like \"Answer concisely: 4444+5559=\" they answer contains \"10003\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fade73",
   "metadata": {},
   "source": [
    "# Martian AI Model Names List\n",
    "Extracted from https://app.withmartian.com/docs/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6de66cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of models: 225\n",
      "First 5 models: ['martian/code', 'agentica-org/deepcoder-14b-preview', 'ai21/jamba-1.6-large', 'ai21/jamba-1.6-mini', 'aion-labs/aion-rp-llama-3.1-8b']\n",
      "Last 5 models: ['x-ai/grok-3', 'x-ai/grok-3-beta', 'x-ai/grok-3-mini', 'x-ai/grok-3-mini-beta', 'x-ai/grok-4']\n",
      "Number of providers: 51\n",
      "Models per provider:\n",
      "  agentica-org: 1 models\n",
      "  ai21: 2 models\n",
      "  aion-labs: 1 models\n",
      "  alfredpros: 1 models\n",
      "  alpindale: 1 models\n",
      "  amazon: 3 models\n",
      "  anthracite-org: 1 models\n",
      "  anthropic: 9 models\n",
      "  arcee-ai: 5 models\n",
      "  arliai: 1 models\n",
      "  baidu: 1 models\n",
      "  bytedance: 1 models\n",
      "  cognitivecomputations: 2 models\n",
      "  cohere: 9 models\n",
      "  deepseek: 12 models\n",
      "  eleutherai: 1 models\n",
      "  eva-unit-01: 1 models\n",
      "  google: 11 models\n",
      "  gryphe: 1 models\n",
      "  inception: 2 models\n",
      "  infermatic: 1 models\n",
      "  liquid: 3 models\n",
      "  mancer: 1 models\n",
      "  martian: 1 models\n",
      "  meta-llama: 15 models\n",
      "  microsoft: 7 models\n",
      "  minimax: 1 models\n",
      "  mistralai: 27 models\n",
      "  moonshotai: 2 models\n",
      "  morph: 3 models\n",
      "  neversleep: 3 models\n",
      "  nothingiisreal: 1 models\n",
      "  nousresearch: 5 models\n",
      "  nvidia: 3 models\n",
      "  openai: 29 models\n",
      "  opengvlab: 1 models\n",
      "  perplexity: 6 models\n",
      "  pygmalionai: 1 models\n",
      "  qwen: 19 models\n",
      "  raifle: 1 models\n",
      "  sao10k: 5 models\n",
      "  sarvamai: 1 models\n",
      "  shisa-ai: 1 models\n",
      "  sophosympatheia: 1 models\n",
      "  switchpoint: 1 models\n",
      "  tencent: 1 models\n",
      "  thedrummer: 6 models\n",
      "  thudm: 3 models\n",
      "  tngtech: 1 models\n",
      "  undi95: 2 models\n",
      "  x-ai: 7 models\n"
     ]
    }
   ],
   "source": [
    "martian_models = [\n",
    "    \"martian/code\",\n",
    "    \"agentica-org/deepcoder-14b-preview\",\n",
    "    \"ai21/jamba-1.6-large\",\n",
    "    \"ai21/jamba-1.6-mini\",\n",
    "    \"aion-labs/aion-rp-llama-3.1-8b\",\n",
    "    \"alfredpros/codellama-7b-instruct-solidity\",\n",
    "    \"alpindale/goliath-120b\",\n",
    "    \"amazon/nova-lite-v1\",\n",
    "    \"amazon/nova-micro-v1\",\n",
    "    \"amazon/nova-pro-v1\",\n",
    "    \"anthracite-org/magnum-v4-72b\",\n",
    "    \"anthropic/claude-3-5-haiku-20241022\",\n",
    "    \"anthropic/claude-3-5-sonnet-20240620\",\n",
    "    \"anthropic/claude-3-5-sonnet-20241022\",\n",
    "    \"anthropic/claude-3-7-sonnet-20250219\",\n",
    "    \"anthropic/claude-3-haiku-20240307\",\n",
    "    \"anthropic/claude-3-opus-20240229\",\n",
    "    \"anthropic/claude-opus-4-1-20250805\",\n",
    "    \"anthropic/claude-opus-4-20250514\",\n",
    "    \"anthropic/claude-sonnet-4-20250514\",\n",
    "    \"arcee-ai/arcee-blitz\",\n",
    "    \"arcee-ai/caller-large\",\n",
    "    \"arcee-ai/coder-large\",\n",
    "    \"arcee-ai/maestro-reasoning\",\n",
    "    \"arcee-ai/virtuoso-large\",\n",
    "    \"arliai/qwq-32b-arliai-rpr-v1\",\n",
    "    \"baidu/ernie-4.5-300b-a47b\",\n",
    "    \"bytedance/ui-tars-1.5-7b\",\n",
    "    \"cognitivecomputations/dolphin-mixtral-8x22b\",\n",
    "    \"cognitivecomputations/dolphin3.0-r1-mistral-24b\",\n",
    "    \"cohere/command\",\n",
    "    \"cohere/command-a\",\n",
    "    \"cohere/command-r\",\n",
    "    \"cohere/command-r-03-2024\",\n",
    "    \"cohere/command-r-08-2024\",\n",
    "    \"cohere/command-r-plus\",\n",
    "    \"cohere/command-r-plus-04-2024\",\n",
    "    \"cohere/command-r-plus-08-2024\",\n",
    "    \"cohere/command-r7b-12-2024\",\n",
    "    \"deepseek/deepseek-chat\",\n",
    "    \"deepseek/deepseek-chat-v3-0324\",\n",
    "    \"deepseek/deepseek-prover-v2\",\n",
    "    \"deepseek/deepseek-r1\",\n",
    "    \"deepseek/deepseek-r1-0528\",\n",
    "    \"deepseek/deepseek-r1-0528-qwen3-8b\",\n",
    "    \"deepseek/deepseek-r1-distill-llama-70b\",\n",
    "    \"deepseek/deepseek-r1-distill-llama-8b\",\n",
    "    \"deepseek/deepseek-r1-distill-qwen-1.5b\",\n",
    "    \"deepseek/deepseek-r1-distill-qwen-14b\",\n",
    "    \"deepseek/deepseek-r1-distill-qwen-32b\",\n",
    "    \"deepseek/deepseek-r1-distill-qwen-7b\",\n",
    "    \"eleutherai/llemma_7b\",\n",
    "    \"eva-unit-01/eva-qwen-2.5-72b\",\n",
    "    \"google/gemini-2.0-flash-001\",\n",
    "    \"google/gemini-2.0-flash-lite-001\",\n",
    "    \"google/gemini-2.5-flash\",\n",
    "    \"google/gemini-2.5-flash-lite\",\n",
    "    \"google/gemini-2.5-flash-lite-preview-06-17\",\n",
    "    \"google/gemini-2.5-pro\",\n",
    "    \"google/gemini-2.5-pro-preview-05-06\",\n",
    "    \"google/gemma-3-12b-it\",\n",
    "    \"google/gemma-3-27b-it\",\n",
    "    \"google/gemma-3-4b-it\",\n",
    "    \"google/gemma-3n-e4b-it\",\n",
    "    \"gryphe/mythomax-l2-13b\",\n",
    "    \"inception/mercury\",\n",
    "    \"inception/mercury-coder\",\n",
    "    \"infermatic/mn-inferor-12b\",\n",
    "    \"liquid/lfm-3b\",\n",
    "    \"liquid/lfm-40b\",\n",
    "    \"liquid/lfm-7b\",\n",
    "    \"mancer/weaver\",\n",
    "    \"meta-llama/llama-3-70b-instruct\",\n",
    "    \"meta-llama/llama-3-8b-instruct\",\n",
    "    \"meta-llama/llama-3.1-405b\",\n",
    "    \"meta-llama/llama-3.1-70b-instruct\",\n",
    "    \"meta-llama/llama-3.1-8b-instruct\",\n",
    "    \"meta-llama/llama-3.2-11b-vision-instruct\",\n",
    "    \"meta-llama/llama-3.2-1b-instruct\",\n",
    "    \"meta-llama/llama-3.2-3b-instruct\",\n",
    "    \"meta-llama/llama-3.2-90b-vision-instruct\",\n",
    "    \"meta-llama/llama-3.3-70b-instruct\",\n",
    "    \"meta-llama/llama-4-maverick\",\n",
    "    \"meta-llama/llama-4-scout\",\n",
    "    \"meta-llama/llama-guard-2-8b\",\n",
    "    \"meta-llama/llama-guard-3-8b\",\n",
    "    \"meta-llama/llama-guard-4-12b\",\n",
    "    \"microsoft/phi-3-medium-128k-instruct\",\n",
    "    \"microsoft/phi-3-mini-128k-instruct\",\n",
    "    \"microsoft/phi-3.5-mini-128k-instruct\",\n",
    "    \"microsoft/phi-4\",\n",
    "    \"microsoft/phi-4-multimodal-instruct\",\n",
    "    \"microsoft/phi-4-reasoning-plus\",\n",
    "    \"microsoft/wizardlm-2-8x22b\",\n",
    "    \"minimax/minimax-m1\",\n",
    "    \"mistralai/codestral-2501\",\n",
    "    \"mistralai/devstral-medium\",\n",
    "    \"mistralai/devstral-small\",\n",
    "    \"mistralai/devstral-small-2505\",\n",
    "    \"mistralai/magistral-medium-2506\",\n",
    "    \"mistralai/magistral-medium-2506:thinking\",\n",
    "    \"mistralai/magistral-small-2506\",\n",
    "    \"mistralai/ministral-3b\",\n",
    "    \"mistralai/ministral-8b\",\n",
    "    \"mistralai/mistral-7b-instruct\",\n",
    "    \"mistralai/mistral-7b-instruct-v0.1\",\n",
    "    \"mistralai/mistral-7b-instruct-v0.2\",\n",
    "    \"mistralai/mistral-7b-instruct-v0.3\",\n",
    "    \"mistralai/mistral-large\",\n",
    "    \"mistralai/mistral-large-2407\",\n",
    "    \"mistralai/mistral-large-2411\",\n",
    "    \"mistralai/mistral-medium-3\",\n",
    "    \"mistralai/mistral-nemo\",\n",
    "    \"mistralai/mistral-saba\",\n",
    "    \"mistralai/mistral-small\",\n",
    "    \"mistralai/mistral-small-24b-instruct-2501\",\n",
    "    \"mistralai/mistral-small-3.1-24b-instruct\",\n",
    "    \"mistralai/mistral-small-3.2-24b-instruct\",\n",
    "    \"mistralai/mistral-tiny\",\n",
    "    \"mistralai/mixtral-8x22b-instruct\",\n",
    "    \"mistralai/mixtral-8x7b-instruct\",\n",
    "    \"mistralai/pixtral-large-2411\",\n",
    "    \"moonshotai/kimi-k2\",\n",
    "    \"moonshotai/kimi-vl-a3b-thinking\",\n",
    "    \"morph/morph-v2\",\n",
    "    \"morph/morph-v3-fast\",\n",
    "    \"morph/morph-v3-large\",\n",
    "    \"neversleep/llama-3-lumimaid-70b\",\n",
    "    \"neversleep/llama-3.1-lumimaid-8b\",\n",
    "    \"neversleep/noromaid-20b\",\n",
    "    \"nothingiisreal/mn-celeste-12b\",\n",
    "    \"nousresearch/deephermes-3-mistral-24b-preview\",\n",
    "    \"nousresearch/hermes-2-pro-llama-3-8b\",\n",
    "    \"nousresearch/hermes-3-llama-3.1-405b\",\n",
    "    \"nousresearch/hermes-3-llama-3.1-70b\",\n",
    "    \"nousresearch/nous-hermes-2-mixtral-8x7b-dpo\",\n",
    "    \"nvidia/llama-3.1-nemotron-70b-instruct\",\n",
    "    \"nvidia/llama-3.1-nemotron-ultra-253b-v1\",\n",
    "    \"nvidia/llama-3.3-nemotron-super-49b-v1\",\n",
    "    \"openai/chatgpt-4o-latest\",\n",
    "    \"openai/gpt-3.5-turbo\",\n",
    "    \"openai/gpt-3.5-turbo-16k\",\n",
    "    \"openai/gpt-4\",\n",
    "    \"openai/gpt-4-0314\",\n",
    "    \"openai/gpt-4-1106-preview\",\n",
    "    \"openai/gpt-4-turbo\",\n",
    "    \"openai/gpt-4-turbo-preview\",\n",
    "    \"openai/gpt-4.1\",\n",
    "    \"openai/gpt-4.1-mini\",\n",
    "    \"openai/gpt-4.1-nano\",\n",
    "    \"openai/gpt-4o\",\n",
    "    \"openai/gpt-4o-2024-05-13\",\n",
    "    \"openai/gpt-4o-2024-08-06\",\n",
    "    \"openai/gpt-4o-2024-11-20\",\n",
    "    \"openai/gpt-4o-mini\",\n",
    "    \"openai/gpt-4o-mini-2024-07-18\",\n",
    "    \"openai/gpt-4o-mini-search-preview\",\n",
    "    \"openai/gpt-4o-search-preview\",\n",
    "    \"openai/gpt-5\",\n",
    "    \"openai/gpt-5-mini\",\n",
    "    \"openai/gpt-5-nano\",\n",
    "    \"openai/o1\",\n",
    "    \"openai/o1-mini\",\n",
    "    \"openai/o1-mini-2024-09-12\",\n",
    "    \"openai/o1-preview\",\n",
    "    \"openai/o1-preview-2024-09-12\",\n",
    "    \"openai/o3-mini\",\n",
    "    \"openai/o4-mini\",\n",
    "    \"opengvlab/internvl3-14b\",\n",
    "    \"perplexity/r1-1776\",\n",
    "    \"perplexity/sonar\",\n",
    "    \"perplexity/sonar-deep-research\",\n",
    "    \"perplexity/sonar-pro\",\n",
    "    \"perplexity/sonar-reasoning\",\n",
    "    \"perplexity/sonar-reasoning-pro\",\n",
    "    \"pygmalionai/mythalion-13b\",\n",
    "    \"qwen/qwen-2-72b-instruct\",\n",
    "    \"qwen/qwen-2.5-72b-instruct\",\n",
    "    \"qwen/qwen-2.5-7b-instruct\",\n",
    "    \"qwen/qwen-2.5-coder-32b-instruct\",\n",
    "    \"qwen/qwen-2.5-vl-7b-instruct\",\n",
    "    \"qwen/qwen-max\",\n",
    "    \"qwen/qwen-plus\",\n",
    "    \"qwen/qwen-turbo\",\n",
    "    \"qwen/qwen-vl-max\",\n",
    "    \"qwen/qwen2.5-vl-32b-instruct\",\n",
    "    \"qwen/qwen2.5-vl-72b-instruct\",\n",
    "    \"qwen/qwen3-14b\",\n",
    "    \"qwen/qwen3-235b-a22b\",\n",
    "    \"qwen/qwen3-235b-a22b-07-25\",\n",
    "    \"qwen/qwen3-30b-a3b\",\n",
    "    \"qwen/qwen3-32b\",\n",
    "    \"qwen/qwen3-8b\",\n",
    "    \"qwen/qwen3-coder\",\n",
    "    \"qwen/qwq-32b\",\n",
    "    \"raifle/sorcererlm-8x22b\",\n",
    "    \"sao10k/fimbulvetr-11b-v2\",\n",
    "    \"sao10k/l3-euryale-70b\",\n",
    "    \"sao10k/l3-lunaris-8b\",\n",
    "    \"sao10k/l3.1-euryale-70b\",\n",
    "    \"sao10k/l3.3-euryale-70b\",\n",
    "    \"sarvamai/sarvam-m\",\n",
    "    \"shisa-ai/shisa-v2-llama3.3-70b\",\n",
    "    \"sophosympatheia/midnight-rose-70b\",\n",
    "    \"switchpoint/router\",\n",
    "    \"tencent/hunyuan-a13b-instruct\",\n",
    "    \"thedrummer/anubis-70b-v1.1\",\n",
    "    \"thedrummer/anubis-pro-105b-v1\",\n",
    "    \"thedrummer/rocinante-12b\",\n",
    "    \"thedrummer/skyfall-36b-v2\",\n",
    "    \"thedrummer/unslopnemo-12b\",\n",
    "    \"thedrummer/valkyrie-49b-v1\",\n",
    "    \"thudm/glm-4-32b\",\n",
    "    \"thudm/glm-4.1v-9b-thinking\",\n",
    "    \"thudm/glm-z1-32b\",\n",
    "    \"tngtech/deepseek-r1t2-chimera\",\n",
    "    \"undi95/remm-slerp-l2-13b\",\n",
    "    \"undi95/toppy-m-7b\",\n",
    "    \"x-ai/grok-2-1212\",\n",
    "    \"x-ai/grok-2-vision-1212\",\n",
    "    \"x-ai/grok-3\",\n",
    "    \"x-ai/grok-3-beta\",\n",
    "    \"x-ai/grok-3-mini\",\n",
    "    \"x-ai/grok-3-mini-beta\",\n",
    "    \"x-ai/grok-4\",\n",
    "]\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Total number of models: {len(martian_models)}\")\n",
    "print(f\"First 5 models: {martian_models[:5]}\")\n",
    "print(f\"Last 5 models: {martian_models[-5:]}\")\n",
    "\n",
    "# Group by provider\n",
    "providers = {}\n",
    "for model in martian_models:\n",
    "    provider = model.split('/')[0]\n",
    "    if provider not in providers:\n",
    "        providers[provider] = []\n",
    "    providers[provider].append(model)\n",
    "\n",
    "print(f\"Number of providers: {len(providers)}\")\n",
    "print(\"Models per provider:\")\n",
    "for provider, models in sorted(providers.items()):\n",
    "    print(f\"  {provider}: {len(models)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a10a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import concurrent.futures\n",
    "import time\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d8ff231",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "MARTIAN_API_KEY = os.getenv(\"MARTIAN_API_KEY\")\n",
    "assert MARTIAN_API_KEY, \"API key not found. Please set MARTIAN_API_KEY in your .env file.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef9d7ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    base_url=\"https://api.withmartian.com/v1\",\n",
    "    api_key=MARTIAN_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7796000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_ground_truth_correct(answer, ground_truth):\n",
    "    \"\"\"\n",
    "    Returns True if the ground_truth appears as the final number in the answer, ignoring whitespace and punctuation.\n",
    "    Accepts answers like '13', '13.', '13**', 'The answer is 13', etc.\n",
    "    \"\"\"\n",
    "    # Remove trailing whitespace and punctuation\n",
    "    answer_clean = answer.strip().rstrip('.!**')\n",
    "    # Find all numbers in the answer\n",
    "    numbers = re.findall(r'\\d+', answer_clean)\n",
    "    # Check if the last number matches ground_truth\n",
    "    return bool(numbers and numbers[-1] == ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa7ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_inference( model_name, prompt, ground_truth):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        max_tokens=100,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    answer = response.choices[0].message.content.strip()\n",
    "    success = is_ground_truth_correct(answer, ground_truth)\n",
    "\n",
    "    return answer, success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64f055f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(the_models, prompt, ground_truth, verbose=False):\n",
    "    results = []\n",
    "    print(f\"Testing {len(the_models)} models...\")\n",
    "    \n",
    "    def call_model(model_name):\n",
    "        try:\n",
    "            answer, success = run_model_inference(model_name, prompt, ground_truth)\n",
    "            return {\n",
    "                \"model\": model_name,\n",
    "                \"success\": success,\n",
    "                \"response\": answer if not success else None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"model\": model_name,\n",
    "                \"success\": False,\n",
    "                \"response\": f\"Error: {str(e)}\"\n",
    "            }\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        for idx, model_name in enumerate(the_models):\n",
    "            future = executor.submit(call_model, model_name)\n",
    "            try:\n",
    "                result = future.result(timeout=10)\n",
    "            except concurrent.futures.TimeoutError:\n",
    "                result = {\n",
    "                    \"model\": model_name,\n",
    "                    \"success\": False,\n",
    "                    \"response\": \"Timeout after 10 seconds\"\n",
    "                }\n",
    "            results.append(result)\n",
    "            print(f\"[{idx+1}/{len(the_models)}] {model_name}: {'SUCCESS' if result['success'] else 'FAIL:'+str(result['response'])}\")\n",
    "    \n",
    "    successes = [r['model'] for r in results if r['success']]\n",
    "    failures = [{\"model\": r['model'], \"response\": r['response']} for r in results if not r['success']]\n",
    "    print(f\"\\nTotal Successes: {len(successes)}\")\n",
    "    print(f\"Total Failures: {len(failures)}\")\n",
    "    return {\"successes\": successes, \"failures\": failures}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "277fb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_progressive(the_models, tests, max_workers=8):\n",
    "    model_scores = []\n",
    "\n",
    "    def score_model(model_name):\n",
    "        score = 0\n",
    "        for test_idx, (prompt, ground_truth) in enumerate(tests):\n",
    "            try:\n",
    "                answer, success = run_model_inference(model_name, prompt, ground_truth)\n",
    "                if success:\n",
    "                    score = test_idx + 1\n",
    "                else:\n",
    "                    break\n",
    "            except openai.APIError as e:\n",
    "                if hasattr(e, 'status_code'):\n",
    "                    score = -e.status_code\n",
    "                else:\n",
    "                    score = -999\n",
    "                break\n",
    "            except Exception as e:\n",
    "                score = -999\n",
    "                break\n",
    "        return {\"model\": model_name, \"score\": score}\n",
    "\n",
    "    print(f\"Evaluating {len(the_models)} models concurrently with {max_workers} workers...\")\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_model = {executor.submit(score_model, model_name): model_name for model_name in the_models}\n",
    "        for idx, future in enumerate(as_completed(future_to_model), 1):\n",
    "            model_name = future_to_model[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "            except Exception as exc:\n",
    "                result = {\"model\": model_name, \"score\": -999}\n",
    "            print(f\"[{idx}/{len(the_models)}] {result['model']}: Score = {result['score']}\")\n",
    "            model_scores.append(result)\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d13382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [\n",
    "    [\"Answer concisely: 4+9=\", \"13\"],\n",
    "    [\"Answer concisely: 44+59=\", \"103\"],\n",
    "    [\"Answer concisely: 444+559=\", \"1003\"],\n",
    "    [\"Answer concisely: 4444+5559=\", \"10003\"],\n",
    "    [\"Answer concisely: 44444+55559=\", \"100003\"],\n",
    "    [\"Answer concisely: 444444+555559=\", \"1000003\"],\n",
    "    [\"Answer concisely: 4444444+5555559=\", \"10000003\"],\n",
    "    [\"Answer concisely: 44444444+55555559=\", \"100000003\"],\n",
    "    [\"Answer concisely: 444444444+555555559=\", \"1000000003\"],\n",
    "    [\"Answer concisely: 4444444444+5555555559=\", \"10000000003\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2af9c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the_models = martian_models[:5]\n",
    "#results = test_models(the_models, \"Answer concisely: 44+59=\", \"103\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a759f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 225 models concurrently with 8 workers...\n",
      "[1/225] ai21/jamba-1.6-large: Score = -400\n",
      "[2/225] martian/code: Score = -400\n",
      "[3/225] ai21/jamba-1.6-mini: Score = -400\n",
      "[1/225] ai21/jamba-1.6-large: Score = -400\n",
      "[2/225] martian/code: Score = -400\n",
      "[3/225] ai21/jamba-1.6-mini: Score = -400\n",
      "[4/225] alfredpros/codellama-7b-instruct-solidity: Score = 0\n",
      "[4/225] alfredpros/codellama-7b-instruct-solidity: Score = 0\n",
      "[5/225] anthropic/claude-3-5-haiku-20241022: Score = 2\n",
      "[5/225] anthropic/claude-3-5-haiku-20241022: Score = 2\n",
      "[6/225] aion-labs/aion-rp-llama-3.1-8b: Score = 3\n",
      "[6/225] aion-labs/aion-rp-llama-3.1-8b: Score = 3\n",
      "[7/225] anthracite-org/magnum-v4-72b: Score = 3\n",
      "[8/225] agentica-org/deepcoder-14b-preview: Score = -502\n",
      "[7/225] anthracite-org/magnum-v4-72b: Score = 3\n",
      "[8/225] agentica-org/deepcoder-14b-preview: Score = -502\n",
      "[9/225] amazon/nova-lite-v1: Score = 3\n",
      "[9/225] amazon/nova-lite-v1: Score = 3\n",
      "[10/225] anthropic/claude-3-5-sonnet-20240620: Score = 3\n",
      "[10/225] anthropic/claude-3-5-sonnet-20240620: Score = 3\n",
      "[11/225] alpindale/goliath-120b: Score = 2\n",
      "[11/225] alpindale/goliath-120b: Score = 2\n",
      "[12/225] anthropic/claude-3-opus-20240229: Score = 2\n",
      "[12/225] anthropic/claude-3-opus-20240229: Score = 2\n",
      "[13/225] amazon/nova-micro-v1: Score = 5\n",
      "[14/225] arcee-ai/arcee-blitz: Score = -400\n",
      "[13/225] amazon/nova-micro-v1: Score = 5\n",
      "[14/225] arcee-ai/arcee-blitz: Score = -400\n",
      "[15/225] arcee-ai/caller-large: Score = -400\n",
      "[15/225] arcee-ai/caller-large: Score = -400\n",
      "[16/225] anthropic/claude-3-haiku-20240307: Score = 7\n",
      "[16/225] anthropic/claude-3-haiku-20240307: Score = 7\n",
      "[17/225] anthropic/claude-3-5-sonnet-20241022: Score = 3\n",
      "[17/225] anthropic/claude-3-5-sonnet-20241022: Score = 3\n",
      "[18/225] arcee-ai/maestro-reasoning: Score = 1\n",
      "[18/225] arcee-ai/maestro-reasoning: Score = 1\n",
      "[19/225] anthropic/claude-3-7-sonnet-20250219: Score = 5\n",
      "[19/225] anthropic/claude-3-7-sonnet-20250219: Score = 5\n",
      "[20/225] arcee-ai/virtuoso-large: Score = 3\n",
      "[20/225] arcee-ai/virtuoso-large: Score = 3\n",
      "[21/225] arcee-ai/coder-large: Score = 8\n",
      "[21/225] arcee-ai/coder-large: Score = 8\n",
      "[22/225] amazon/nova-pro-v1: Score = 10\n",
      "[22/225] amazon/nova-pro-v1: Score = 10\n",
      "[23/225] bytedance/ui-tars-1.5-7b: Score = 1\n",
      "[24/225] arliai/qwq-32b-arliai-rpr-v1: Score = -502\n",
      "[23/225] bytedance/ui-tars-1.5-7b: Score = 1\n",
      "[24/225] arliai/qwq-32b-arliai-rpr-v1: Score = -502\n",
      "[25/225] anthropic/claude-opus-4-1-20250805: Score = 6\n",
      "[25/225] anthropic/claude-opus-4-1-20250805: Score = 6\n",
      "[26/225] anthropic/claude-sonnet-4-20250514: Score = 8\n",
      "[26/225] anthropic/claude-sonnet-4-20250514: Score = 8\n",
      "[27/225] anthropic/claude-opus-4-20250514: Score = 6\n",
      "[28/225] cognitivecomputations/dolphin-mixtral-8x22b: Score = 3\n",
      "[27/225] anthropic/claude-opus-4-20250514: Score = 6\n",
      "[28/225] cognitivecomputations/dolphin-mixtral-8x22b: Score = 3\n",
      "[29/225] cognitivecomputations/dolphin3.0-r1-mistral-24b: Score = -502\n",
      "[29/225] cognitivecomputations/dolphin3.0-r1-mistral-24b: Score = -502\n",
      "[30/225] cohere/command: Score = 2\n",
      "[30/225] cohere/command: Score = 2\n",
      "[31/225] cohere/command-r: Score = 3\n",
      "[31/225] cohere/command-r: Score = 3\n",
      "[32/225] cohere/command-r-03-2024: Score = 3\n",
      "[32/225] cohere/command-r-03-2024: Score = 3\n",
      "[33/225] cohere/command-a: Score = 2\n",
      "[33/225] cohere/command-a: Score = 2\n",
      "[34/225] cohere/command-r-08-2024: Score = 5\n",
      "[34/225] cohere/command-r-08-2024: Score = 5\n",
      "[35/225] cohere/command-r-plus-08-2024: Score = 2\n",
      "[35/225] cohere/command-r-plus-08-2024: Score = 2\n",
      "[36/225] cohere/command-r-plus: Score = 2\n",
      "[36/225] cohere/command-r-plus: Score = 2\n",
      "[37/225] cohere/command-r-plus-04-2024: Score = 3\n",
      "[38/225] deepseek/deepseek-chat: Score = 4\n",
      "[37/225] cohere/command-r-plus-04-2024: Score = 3\n",
      "[38/225] deepseek/deepseek-chat: Score = 4\n",
      "[39/225] cohere/command-r7b-12-2024: Score = 4\n",
      "[40/225] baidu/ernie-4.5-300b-a47b: Score = 10\n",
      "[39/225] cohere/command-r7b-12-2024: Score = 4\n",
      "[40/225] baidu/ernie-4.5-300b-a47b: Score = 10\n",
      "[41/225] deepseek/deepseek-r1-0528: Score = 0\n",
      "[42/225] deepseek/deepseek-r1-distill-qwen-1.5b: Score = -400\n",
      "[41/225] deepseek/deepseek-r1-0528: Score = 0\n",
      "[42/225] deepseek/deepseek-r1-distill-qwen-1.5b: Score = -400\n",
      "[43/225] deepseek/deepseek-r1-distill-llama-70b: Score = 0\n",
      "[44/225] deepseek/deepseek-r1-distill-qwen-7b: Score = -400\n",
      "[43/225] deepseek/deepseek-r1-distill-llama-70b: Score = 0\n",
      "[44/225] deepseek/deepseek-r1-distill-qwen-7b: Score = -400\n",
      "[45/225] deepseek/deepseek-prover-v2: Score = 3\n",
      "[46/225] eva-unit-01/eva-qwen-2.5-72b: Score = -400\n",
      "[45/225] deepseek/deepseek-prover-v2: Score = 3\n",
      "[46/225] eva-unit-01/eva-qwen-2.5-72b: Score = -400\n",
      "[47/225] deepseek/deepseek-r1-0528-qwen3-8b: Score = 0\n",
      "[47/225] deepseek/deepseek-r1-0528-qwen3-8b: Score = 0\n",
      "[48/225] deepseek/deepseek-r1-distill-qwen-14b: Score = 0\n",
      "[48/225] deepseek/deepseek-r1-distill-qwen-14b: Score = 0\n",
      "[49/225] deepseek/deepseek-chat-v3-0324: Score = 5\n",
      "[49/225] deepseek/deepseek-chat-v3-0324: Score = 5\n",
      "[50/225] google/gemini-2.0-flash-lite-001: Score = 3\n",
      "[50/225] google/gemini-2.0-flash-lite-001: Score = 3\n",
      "[51/225] deepseek/deepseek-r1-distill-qwen-32b: Score = 1\n",
      "[52/225] deepseek/deepseek-r1-distill-llama-8b: Score = 1\n",
      "[51/225] deepseek/deepseek-r1-distill-qwen-32b: Score = 1\n",
      "[52/225] deepseek/deepseek-r1-distill-llama-8b: Score = 1\n",
      "[53/225] google/gemini-2.5-flash: Score = -999\n",
      "[54/225] eleutherai/llemma_7b: Score = 0\n",
      "[53/225] google/gemini-2.5-flash: Score = -999\n",
      "[54/225] eleutherai/llemma_7b: Score = 0\n",
      "[55/225] google/gemini-2.5-pro: Score = -999\n",
      "[56/225] google/gemini-2.5-pro-preview-05-06: Score = -999\n",
      "[55/225] google/gemini-2.5-pro: Score = -999\n",
      "[56/225] google/gemini-2.5-pro-preview-05-06: Score = -999\n",
      "[57/225] google/gemini-2.5-flash-lite: Score = 3\n",
      "[57/225] google/gemini-2.5-flash-lite: Score = 3\n",
      "[58/225] google/gemini-2.0-flash-001: Score = 8\n",
      "[58/225] google/gemini-2.0-flash-001: Score = 8\n",
      "[59/225] google/gemma-3n-e4b-it: Score = 3\n",
      "[59/225] google/gemma-3n-e4b-it: Score = 3\n",
      "[60/225] google/gemini-2.5-flash-lite-preview-06-17: Score = 10\n",
      "[60/225] google/gemini-2.5-flash-lite-preview-06-17: Score = 10\n",
      "[61/225] inception/mercury: Score = 4\n",
      "[62/225] google/gemma-3-4b-it: Score = 4\n",
      "[63/225] liquid/lfm-40b: Score = -400\n",
      "[61/225] inception/mercury: Score = 4\n",
      "[62/225] google/gemma-3-4b-it: Score = 4\n",
      "[63/225] liquid/lfm-40b: Score = -400\n",
      "[64/225] infermatic/mn-inferor-12b: Score = 0\n",
      "[64/225] infermatic/mn-inferor-12b: Score = 0\n",
      "[65/225] deepseek/deepseek-r1: Score = 2\n",
      "[65/225] deepseek/deepseek-r1: Score = 2\n",
      "[66/225] google/gemma-3-12b-it: Score = 5\n",
      "[66/225] google/gemma-3-12b-it: Score = 5\n",
      "[67/225] mancer/weaver: Score = 0\n",
      "[67/225] mancer/weaver: Score = 0\n",
      "[68/225] liquid/lfm-7b: Score = 2\n",
      "[68/225] liquid/lfm-7b: Score = 2\n",
      "[69/225] gryphe/mythomax-l2-13b: Score = 2\n",
      "[69/225] gryphe/mythomax-l2-13b: Score = 2\n",
      "[70/225] liquid/lfm-3b: Score = 2\n",
      "[70/225] liquid/lfm-3b: Score = 2\n",
      "[71/225] google/gemma-3-27b-it: Score = -502\n",
      "[71/225] google/gemma-3-27b-it: Score = -502\n",
      "[72/225] inception/mercury-coder: Score = 10\n",
      "[72/225] inception/mercury-coder: Score = 10\n",
      "[73/225] meta-llama/llama-3.1-8b-instruct: Score = 2\n",
      "[73/225] meta-llama/llama-3.1-8b-instruct: Score = 2\n",
      "[74/225] meta-llama/llama-3.2-11b-vision-instruct: Score = 2\n",
      "[75/225] meta-llama/llama-3-8b-instruct: Score = 3\n",
      "[74/225] meta-llama/llama-3.2-11b-vision-instruct: Score = 2\n",
      "[75/225] meta-llama/llama-3-8b-instruct: Score = 3\n",
      "[76/225] meta-llama/llama-3-70b-instruct: Score = 4\n",
      "[77/225] meta-llama/llama-3.2-3b-instruct: Score = 2\n",
      "[76/225] meta-llama/llama-3-70b-instruct: Score = 4\n",
      "[77/225] meta-llama/llama-3.2-3b-instruct: Score = 2\n",
      "[78/225] meta-llama/llama-3.1-70b-instruct: Score = 4\n",
      "[78/225] meta-llama/llama-3.1-70b-instruct: Score = 4\n",
      "[79/225] meta-llama/llama-3.2-1b-instruct: Score = 3\n",
      "[79/225] meta-llama/llama-3.2-1b-instruct: Score = 3\n",
      "[80/225] meta-llama/llama-guard-2-8b: Score = 1\n",
      "[80/225] meta-llama/llama-guard-2-8b: Score = 1\n",
      "[81/225] meta-llama/llama-guard-4-12b: Score = 0\n",
      "[81/225] meta-llama/llama-guard-4-12b: Score = 0\n",
      "[82/225] meta-llama/llama-3.1-405b: Score = 0\n",
      "[82/225] meta-llama/llama-3.1-405b: Score = 0\n",
      "[83/225] meta-llama/llama-4-maverick: Score = 4\n",
      "[83/225] meta-llama/llama-4-maverick: Score = 4\n",
      "[84/225] meta-llama/llama-guard-3-8b: Score = 2\n",
      "[84/225] meta-llama/llama-guard-3-8b: Score = 2\n",
      "[85/225] meta-llama/llama-4-scout: Score = 4\n",
      "[85/225] meta-llama/llama-4-scout: Score = 4\n",
      "[86/225] meta-llama/llama-3.3-70b-instruct: Score = 5\n",
      "[86/225] meta-llama/llama-3.3-70b-instruct: Score = 5\n",
      "[87/225] meta-llama/llama-3.2-90b-vision-instruct: Score = 4\n",
      "[87/225] meta-llama/llama-3.2-90b-vision-instruct: Score = 4\n",
      "[88/225] microsoft/phi-3-medium-128k-instruct: Score = 3\n",
      "[88/225] microsoft/phi-3-medium-128k-instruct: Score = 3\n",
      "[89/225] microsoft/phi-3-mini-128k-instruct: Score = 4\n",
      "[89/225] microsoft/phi-3-mini-128k-instruct: Score = 4\n",
      "[90/225] microsoft/phi-4: Score = 2\n",
      "[90/225] microsoft/phi-4: Score = 2\n",
      "[91/225] microsoft/phi-3.5-mini-128k-instruct: Score = 4\n",
      "[91/225] microsoft/phi-3.5-mini-128k-instruct: Score = 4\n",
      "[92/225] mistralai/codestral-2501: Score = 3\n",
      "[92/225] mistralai/codestral-2501: Score = 3\n",
      "[93/225] microsoft/wizardlm-2-8x22b: Score = 3\n",
      "[93/225] microsoft/wizardlm-2-8x22b: Score = 3\n",
      "[94/225] microsoft/phi-4-reasoning-plus: Score = 3\n",
      "[94/225] microsoft/phi-4-reasoning-plus: Score = 3\n",
      "[95/225] mistralai/magistral-medium-2506:thinking: Score = 0\n",
      "[95/225] mistralai/magistral-medium-2506:thinking: Score = 0\n",
      "[96/225] minimax/minimax-m1: Score = 0\n",
      "[96/225] minimax/minimax-m1: Score = 0\n",
      "[97/225] mistralai/devstral-small: Score = 3\n",
      "[97/225] mistralai/devstral-small: Score = 3\n",
      "[98/225] mistralai/magistral-small-2506: Score = 2\n",
      "[98/225] mistralai/magistral-small-2506: Score = 2\n",
      "[99/225] mistralai/devstral-medium: Score = 6\n",
      "[100/225] mistralai/mistral-7b-instruct-v0.2: Score = -400\n",
      "[101/225] mistralai/magistral-medium-2506: Score = 4\n",
      "[99/225] mistralai/devstral-medium: Score = 6\n",
      "[100/225] mistralai/mistral-7b-instruct-v0.2: Score = -400\n",
      "[101/225] mistralai/magistral-medium-2506: Score = 4\n",
      "[102/225] mistralai/devstral-small-2505: Score = 5\n",
      "[103/225] mistralai/ministral-8b: Score = 3\n",
      "[102/225] mistralai/devstral-small-2505: Score = 5\n",
      "[103/225] mistralai/ministral-8b: Score = 3\n",
      "[104/225] microsoft/phi-4-multimodal-instruct: Score = 8\n",
      "[104/225] microsoft/phi-4-multimodal-instruct: Score = 8\n",
      "[105/225] mistralai/ministral-3b: Score = 4\n",
      "[105/225] mistralai/ministral-3b: Score = 4\n",
      "[106/225] mistralai/mistral-7b-instruct: Score = 3\n",
      "[106/225] mistralai/mistral-7b-instruct: Score = 3\n",
      "[107/225] mistralai/mistral-7b-instruct-v0.3: Score = 4\n",
      "[107/225] mistralai/mistral-7b-instruct-v0.3: Score = 4\n",
      "[108/225] mistralai/mistral-nemo: Score = 2\n",
      "[109/225] mistralai/mistral-7b-instruct-v0.1: Score = 3\n",
      "[108/225] mistralai/mistral-nemo: Score = 2\n",
      "[109/225] mistralai/mistral-7b-instruct-v0.1: Score = 3\n",
      "[110/225] mistralai/mistral-large-2407: Score = 4\n",
      "[110/225] mistralai/mistral-large-2407: Score = 4\n",
      "[111/225] mistralai/mistral-saba: Score = 3\n",
      "[112/225] mistralai/mistral-medium-3: Score = 5\n",
      "[111/225] mistralai/mistral-saba: Score = 3\n",
      "[112/225] mistralai/mistral-medium-3: Score = 5\n",
      "[113/225] mistralai/mistral-large: Score = 8\n",
      "[113/225] mistralai/mistral-large: Score = 8\n",
      "[114/225] mistralai/mistral-small-3.2-24b-instruct: Score = 2\n",
      "[114/225] mistralai/mistral-small-3.2-24b-instruct: Score = 2\n",
      "[115/225] mistralai/mistral-small-3.1-24b-instruct: Score = 3\n",
      "[115/225] mistralai/mistral-small-3.1-24b-instruct: Score = 3\n",
      "[116/225] mistralai/mistral-large-2411: Score = 10\n",
      "[116/225] mistralai/mistral-large-2411: Score = 10\n",
      "[117/225] mistralai/mistral-tiny: Score = 3\n",
      "[117/225] mistralai/mistral-tiny: Score = 3\n",
      "[118/225] morph/morph-v2: Score = -400\n",
      "[118/225] morph/morph-v2: Score = -400\n",
      "[119/225] mistralai/mixtral-8x7b-instruct: Score = 1\n",
      "[119/225] mistralai/mixtral-8x7b-instruct: Score = 1\n",
      "[120/225] morph/morph-v3-fast: Score = 0\n",
      "[120/225] morph/morph-v3-fast: Score = 0\n",
      "[121/225] mistralai/mistral-small: Score = 5\n",
      "[122/225] mistralai/mistral-small-24b-instruct-2501: Score = 5\n",
      "[123/225] mistralai/pixtral-large-2411: Score = 2\n",
      "[121/225] mistralai/mistral-small: Score = 5\n",
      "[122/225] mistralai/mistral-small-24b-instruct-2501: Score = 5\n",
      "[123/225] mistralai/pixtral-large-2411: Score = 2\n",
      "[124/225] nothingiisreal/mn-celeste-12b: Score = -400\n",
      "[124/225] nothingiisreal/mn-celeste-12b: Score = -400\n",
      "[125/225] mistralai/mixtral-8x22b-instruct: Score = 3\n",
      "[125/225] mistralai/mixtral-8x22b-instruct: Score = 3\n",
      "[126/225] moonshotai/kimi-vl-a3b-thinking: Score = -502\n",
      "[126/225] moonshotai/kimi-vl-a3b-thinking: Score = -502\n",
      "[127/225] moonshotai/kimi-k2: Score = 4\n",
      "[127/225] moonshotai/kimi-k2: Score = 4\n",
      "[128/225] neversleep/noromaid-20b: Score = 2\n",
      "[129/225] nousresearch/nous-hermes-2-mixtral-8x7b-dpo: Score = -400\n",
      "[130/225] nousresearch/deephermes-3-mistral-24b-preview: Score = -502\n",
      "[128/225] neversleep/noromaid-20b: Score = 2\n",
      "[129/225] nousresearch/nous-hermes-2-mixtral-8x7b-dpo: Score = -400\n",
      "[130/225] nousresearch/deephermes-3-mistral-24b-preview: Score = -502\n",
      "[131/225] morph/morph-v3-large: Score = 5\n",
      "[131/225] morph/morph-v3-large: Score = 5\n",
      "[132/225] nvidia/llama-3.3-nemotron-super-49b-v1: Score = 2\n",
      "[133/225] neversleep/llama-3-lumimaid-70b: Score = 3\n",
      "[134/225] nousresearch/hermes-3-llama-3.1-70b: Score = 1\n",
      "[135/225] nousresearch/hermes-3-llama-3.1-405b: Score = 4\n",
      "[132/225] nvidia/llama-3.3-nemotron-super-49b-v1: Score = 2\n",
      "[133/225] neversleep/llama-3-lumimaid-70b: Score = 3\n",
      "[134/225] nousresearch/hermes-3-llama-3.1-70b: Score = 1\n",
      "[135/225] nousresearch/hermes-3-llama-3.1-405b: Score = 4\n",
      "[136/225] nvidia/llama-3.1-nemotron-ultra-253b-v1: Score = 0\n",
      "[137/225] neversleep/llama-3.1-lumimaid-8b: Score = 2\n",
      "[136/225] nvidia/llama-3.1-nemotron-ultra-253b-v1: Score = 0\n",
      "[137/225] neversleep/llama-3.1-lumimaid-8b: Score = 2\n",
      "[138/225] nousresearch/hermes-2-pro-llama-3-8b: Score = 4\n",
      "[138/225] nousresearch/hermes-2-pro-llama-3-8b: Score = 4\n",
      "[139/225] nvidia/llama-3.1-nemotron-70b-instruct: Score = 4\n",
      "[140/225] openai/chatgpt-4o-latest: Score = 3\n",
      "[139/225] nvidia/llama-3.1-nemotron-70b-instruct: Score = 4\n",
      "[140/225] openai/chatgpt-4o-latest: Score = 3\n",
      "[141/225] openai/gpt-3.5-turbo: Score = 5\n",
      "[141/225] openai/gpt-3.5-turbo: Score = 5\n",
      "[142/225] openai/gpt-3.5-turbo-16k: Score = 5\n",
      "[142/225] openai/gpt-3.5-turbo-16k: Score = 5\n",
      "[143/225] openai/gpt-4.1: Score = 3\n",
      "[143/225] openai/gpt-4.1: Score = 3\n",
      "[144/225] openai/gpt-4.1-nano: Score = 3\n",
      "[144/225] openai/gpt-4.1-nano: Score = 3\n",
      "[145/225] openai/gpt-4-turbo: Score = 5\n",
      "[145/225] openai/gpt-4-turbo: Score = 5\n",
      "[146/225] openai/gpt-4-turbo-preview: Score = 5\n",
      "[146/225] openai/gpt-4-turbo-preview: Score = 5\n",
      "[147/225] openai/gpt-4: Score = 8\n",
      "[147/225] openai/gpt-4: Score = 8\n",
      "[148/225] openai/gpt-4.1-mini: Score = 5\n",
      "[148/225] openai/gpt-4.1-mini: Score = 5\n",
      "[149/225] openai/gpt-4o-2024-11-20: Score = 2\n",
      "[149/225] openai/gpt-4o-2024-11-20: Score = 2\n",
      "[150/225] openai/gpt-4o-2024-08-06: Score = 3\n",
      "[150/225] openai/gpt-4o-2024-08-06: Score = 3\n",
      "[151/225] openai/gpt-4-0314: Score = 10\n",
      "[151/225] openai/gpt-4-0314: Score = 10\n",
      "[152/225] openai/gpt-4-1106-preview: Score = 8\n",
      "[152/225] openai/gpt-4-1106-preview: Score = 8\n",
      "[153/225] openai/gpt-4o: Score = 5\n",
      "[153/225] openai/gpt-4o: Score = 5\n",
      "[154/225] openai/gpt-4o-2024-05-13: Score = 5\n",
      "[154/225] openai/gpt-4o-2024-05-13: Score = 5\n",
      "[155/225] openai/gpt-5-nano: Score = 0\n",
      "[155/225] openai/gpt-5-nano: Score = 0\n",
      "[156/225] openai/gpt-4o-mini-2024-07-18: Score = 5\n",
      "[156/225] openai/gpt-4o-mini-2024-07-18: Score = 5\n",
      "[157/225] openai/o1-mini: Score = 0\n",
      "[158/225] openai/o1-preview: Score = -400\n",
      "[159/225] openai/o1-preview-2024-09-12: Score = -400\n",
      "[157/225] openai/o1-mini: Score = 0\n",
      "[158/225] openai/o1-preview: Score = -400\n",
      "[159/225] openai/o1-preview-2024-09-12: Score = -400\n",
      "[160/225] openai/o1-mini-2024-09-12: Score = 0\n",
      "[160/225] openai/o1-mini-2024-09-12: Score = 0\n",
      "[161/225] openai/o3-mini: Score = 0\n",
      "[161/225] openai/o3-mini: Score = 0\n",
      "[162/225] openai/gpt-5-mini: Score = 2\n",
      "[162/225] openai/gpt-5-mini: Score = 2\n",
      "[163/225] openai/gpt-5: Score = 3\n",
      "[164/225] openai/gpt-4o-mini: Score = 8\n",
      "[163/225] openai/gpt-5: Score = 3\n",
      "[164/225] openai/gpt-4o-mini: Score = 8\n",
      "[165/225] openai/o1: Score = 3\n",
      "[165/225] openai/o1: Score = 3\n",
      "[166/225] opengvlab/internvl3-14b: Score = -502\n",
      "[166/225] opengvlab/internvl3-14b: Score = -502\n",
      "[167/225] perplexity/r1-1776: Score = -502\n",
      "[167/225] perplexity/r1-1776: Score = -502\n",
      "[168/225] openai/o4-mini: Score = 4\n",
      "[168/225] openai/o4-mini: Score = 4\n",
      "[169/225] perplexity/sonar-reasoning: Score = 0\n",
      "[170/225] qwen/qwen-2-72b-instruct: Score = -400\n",
      "[169/225] perplexity/sonar-reasoning: Score = 0\n",
      "[170/225] qwen/qwen-2-72b-instruct: Score = -400\n",
      "[171/225] perplexity/sonar-reasoning-pro: Score = 0\n",
      "[171/225] perplexity/sonar-reasoning-pro: Score = 0\n",
      "[172/225] perplexity/sonar-deep-research: Score = 2\n",
      "[172/225] perplexity/sonar-deep-research: Score = 2\n",
      "[173/225] openai/gpt-4o-mini-search-preview: Score = 10\n",
      "[173/225] openai/gpt-4o-mini-search-preview: Score = 10\n",
      "[174/225] qwen/qwen-2.5-72b-instruct: Score = 3\n",
      "[174/225] qwen/qwen-2.5-72b-instruct: Score = 3\n",
      "[175/225] pygmalionai/mythalion-13b: Score = 6\n",
      "[175/225] pygmalionai/mythalion-13b: Score = 6\n",
      "[176/225] perplexity/sonar-pro: Score = 4\n",
      "[177/225] perplexity/sonar: Score = 5\n",
      "[176/225] perplexity/sonar-pro: Score = 4\n",
      "[177/225] perplexity/sonar: Score = 5\n",
      "[178/225] qwen/qwen-2.5-7b-instruct: Score = 2\n",
      "[178/225] qwen/qwen-2.5-7b-instruct: Score = 2\n",
      "[179/225] qwen/qwen-2.5-coder-32b-instruct: Score = 5\n",
      "[179/225] qwen/qwen-2.5-coder-32b-instruct: Score = 5\n",
      "[180/225] qwen/qwen-2.5-vl-7b-instruct: Score = 2\n",
      "[180/225] qwen/qwen-2.5-vl-7b-instruct: Score = 2\n",
      "[181/225] qwen/qwen-max: Score = 2\n",
      "[181/225] qwen/qwen-max: Score = 2\n",
      "[182/225] qwen/qwen3-235b-a22b: Score = 0\n",
      "[183/225] qwen/qwen2.5-vl-32b-instruct: Score = 3\n",
      "[184/225] qwen/qwen3-235b-a22b-07-25: Score = -400\n",
      "[182/225] qwen/qwen3-235b-a22b: Score = 0\n",
      "[183/225] qwen/qwen2.5-vl-32b-instruct: Score = 3\n",
      "[184/225] qwen/qwen3-235b-a22b-07-25: Score = -400\n",
      "[185/225] qwen/qwen3-14b: Score = 0\n",
      "[185/225] qwen/qwen3-14b: Score = 0\n",
      "[186/225] qwen/qwen3-32b: Score = 0\n",
      "[186/225] qwen/qwen3-32b: Score = 0\n",
      "[187/225] qwen/qwen-plus: Score = 5\n",
      "[187/225] qwen/qwen-plus: Score = 5\n",
      "[188/225] qwen/qwen3-8b: Score = 0\n",
      "[188/225] qwen/qwen3-8b: Score = 0\n",
      "[189/225] qwen/qwen-turbo: Score = 5\n",
      "[190/225] sao10k/fimbulvetr-11b-v2: Score = -400\n",
      "[189/225] qwen/qwen-turbo: Score = 5\n",
      "[190/225] sao10k/fimbulvetr-11b-v2: Score = -400\n",
      "[191/225] qwen/qwen2.5-vl-72b-instruct: Score = 7\n",
      "[191/225] qwen/qwen2.5-vl-72b-instruct: Score = 7\n",
      "[192/225] qwen/qwen3-30b-a3b: Score = 1\n",
      "[193/225] qwen/qwq-32b: Score = 0\n",
      "[192/225] qwen/qwen3-30b-a3b: Score = 1\n",
      "[193/225] qwen/qwq-32b: Score = 0\n",
      "[194/225] qwen/qwen-vl-max: Score = 10\n",
      "[195/225] sarvamai/sarvam-m: Score = -400\n",
      "[194/225] qwen/qwen-vl-max: Score = 10\n",
      "[195/225] sarvamai/sarvam-m: Score = -400\n",
      "[196/225] raifle/sorcererlm-8x22b: Score = 4\n",
      "[196/225] raifle/sorcererlm-8x22b: Score = 4\n",
      "[197/225] sao10k/l3-lunaris-8b: Score = 3\n",
      "[197/225] sao10k/l3-lunaris-8b: Score = 3\n",
      "[198/225] sao10k/l3-euryale-70b: Score = 4\n",
      "[198/225] sao10k/l3-euryale-70b: Score = 4\n",
      "[199/225] shisa-ai/shisa-v2-llama3.3-70b: Score = -502\n",
      "[199/225] shisa-ai/shisa-v2-llama3.3-70b: Score = -502\n",
      "[200/225] sao10k/l3.3-euryale-70b: Score = 4\n",
      "[200/225] sao10k/l3.3-euryale-70b: Score = 4\n",
      "[201/225] sao10k/l3.1-euryale-70b: Score = 4\n",
      "[201/225] sao10k/l3.1-euryale-70b: Score = 4\n",
      "[202/225] sophosympatheia/midnight-rose-70b: Score = 3\n",
      "[202/225] sophosympatheia/midnight-rose-70b: Score = 3\n",
      "[203/225] qwen/qwen3-coder: Score = 10\n",
      "[203/225] qwen/qwen3-coder: Score = 10\n",
      "[204/225] switchpoint/router: Score = 1\n",
      "[205/225] thedrummer/valkyrie-49b-v1: Score = -400\n",
      "[204/225] switchpoint/router: Score = 1\n",
      "[205/225] thedrummer/valkyrie-49b-v1: Score = -400\n",
      "[206/225] thedrummer/anubis-pro-105b-v1: Score = 4\n",
      "[206/225] thedrummer/anubis-pro-105b-v1: Score = 4\n",
      "[207/225] thudm/glm-4.1v-9b-thinking: Score = 1\n",
      "[207/225] thudm/glm-4.1v-9b-thinking: Score = 1\n",
      "[208/225] thudm/glm-4-32b: Score = 4\n",
      "[209/225] tngtech/deepseek-r1t2-chimera: Score = -400\n",
      "[208/225] thudm/glm-4-32b: Score = 4\n",
      "[209/225] tngtech/deepseek-r1t2-chimera: Score = -400\n",
      "[210/225] thedrummer/rocinante-12b: Score = 3\n",
      "[211/225] undi95/toppy-m-7b: Score = -400\n",
      "[210/225] thedrummer/rocinante-12b: Score = 3\n",
      "[211/225] undi95/toppy-m-7b: Score = -400\n",
      "[212/225] thedrummer/unslopnemo-12b: Score = 4\n",
      "[212/225] thedrummer/unslopnemo-12b: Score = 4\n",
      "[213/225] thudm/glm-z1-32b: Score = -502\n",
      "[213/225] thudm/glm-z1-32b: Score = -502\n",
      "[214/225] undi95/remm-slerp-l2-13b: Score = 3\n",
      "[214/225] undi95/remm-slerp-l2-13b: Score = 3\n",
      "[215/225] x-ai/grok-3: Score = 5\n",
      "[215/225] x-ai/grok-3: Score = 5\n",
      "[216/225] x-ai/grok-2-1212: Score = 9\n",
      "[217/225] x-ai/grok-3-beta: Score = 3\n",
      "[216/225] x-ai/grok-2-1212: Score = 9\n",
      "[217/225] x-ai/grok-3-beta: Score = 3\n",
      "[218/225] thedrummer/skyfall-36b-v2: Score = 6\n",
      "[218/225] thedrummer/skyfall-36b-v2: Score = 6\n",
      "[219/225] x-ai/grok-3-mini: Score = 0\n",
      "[219/225] x-ai/grok-3-mini: Score = 0\n",
      "[220/225] x-ai/grok-3-mini-beta: Score = 0\n",
      "[221/225] thedrummer/anubis-70b-v1.1: Score = 4\n",
      "[220/225] x-ai/grok-3-mini-beta: Score = 0\n",
      "[221/225] thedrummer/anubis-70b-v1.1: Score = 4\n",
      "[222/225] x-ai/grok-2-vision-1212: Score = 10\n",
      "[222/225] x-ai/grok-2-vision-1212: Score = 10\n",
      "[223/225] x-ai/grok-4: Score = 1\n",
      "[223/225] x-ai/grok-4: Score = 1\n",
      "[224/225] openai/gpt-4o-search-preview: Score = 10\n",
      "[225/225] tencent/hunyuan-a13b-instruct: Score = 10\n",
      "[224/225] openai/gpt-4o-search-preview: Score = 10\n",
      "[225/225] tencent/hunyuan-a13b-instruct: Score = 10\n"
     ]
    }
   ],
   "source": [
    "the_models = martian_models \n",
    "model_scores = evaluate_models_progressive(the_models, tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d238c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of models: 225\n",
      "Score summary (number of models by score):\n",
      "Score -999: 3 models\n",
      "Score -502: 10 models\n",
      "Score -400: 22 models\n",
      "Score 0: 27 models\n",
      "Score 1: 11 models\n",
      "Score 2: 29 models\n",
      "Score 3: 42 models\n",
      "Score 4: 29 models\n",
      "Score 5: 24 models\n",
      "Score 6: 5 models\n",
      "Score 7: 2 models\n",
      "Score 8: 8 models\n",
      "Score 9: 1 models\n",
      "Score 10: 12 models\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    " \n",
    "# Summarize number of models by score\n",
    "print(f\"Total number of models: {len(martian_models)}\")\n",
    "score_counts = Counter([m['score'] for m in model_scores])\n",
    "print(\"Score summary (number of models by score):\")\n",
    "for score, count in sorted(score_counts.items()):\n",
    "    print(f\"Score {score}: {count} models\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a4ff105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph the results with categorical x-axis for scores\n",
    "scores_sorted = sorted(score_counts.keys(), key=lambda x: (isinstance(x, int), x))\n",
    "counts_sorted = [score_counts[s] for s in scores_sorted]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(range(len(scores_sorted)), counts_sorted, color='skyblue')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Number of Models')\n",
    "plt.title('Number of Models by Score')\n",
    "plt.xticks(range(len(scores_sorted)), [str(s) for s in scores_sorted])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4675d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Models with score -999:\n",
      "  google/gemini-2.5-flash\n",
      "  google/gemini-2.5-pro\n",
      "  google/gemini-2.5-pro-preview-05-06\n",
      "\n",
      "Models with score -502:\n",
      "  agentica-org/deepcoder-14b-preview\n",
      "  arliai/qwq-32b-arliai-rpr-v1\n",
      "  cognitivecomputations/dolphin3.0-r1-mistral-24b\n",
      "  google/gemma-3-27b-it\n",
      "  moonshotai/kimi-vl-a3b-thinking\n",
      "  nousresearch/deephermes-3-mistral-24b-preview\n",
      "  opengvlab/internvl3-14b\n",
      "  perplexity/r1-1776\n",
      "  shisa-ai/shisa-v2-llama3.3-70b\n",
      "  thudm/glm-z1-32b\n",
      "\n",
      "Models with score -400:\n",
      "  ai21/jamba-1.6-large\n",
      "  martian/code\n",
      "  ai21/jamba-1.6-mini\n",
      "  arcee-ai/arcee-blitz\n",
      "  arcee-ai/caller-large\n",
      "  deepseek/deepseek-r1-distill-qwen-1.5b\n",
      "  deepseek/deepseek-r1-distill-qwen-7b\n",
      "  eva-unit-01/eva-qwen-2.5-72b\n",
      "  liquid/lfm-40b\n",
      "  mistralai/mistral-7b-instruct-v0.2\n",
      "  morph/morph-v2\n",
      "  nothingiisreal/mn-celeste-12b\n",
      "  nousresearch/nous-hermes-2-mixtral-8x7b-dpo\n",
      "  openai/o1-preview\n",
      "  openai/o1-preview-2024-09-12\n",
      "  qwen/qwen-2-72b-instruct\n",
      "  qwen/qwen3-235b-a22b-07-25\n",
      "  sao10k/fimbulvetr-11b-v2\n",
      "  sarvamai/sarvam-m\n",
      "  thedrummer/valkyrie-49b-v1\n",
      "  tngtech/deepseek-r1t2-chimera\n",
      "  undi95/toppy-m-7b\n",
      "\n",
      "Models with score 0:\n",
      "  alfredpros/codellama-7b-instruct-solidity\n",
      "  deepseek/deepseek-r1-0528\n",
      "  deepseek/deepseek-r1-distill-llama-70b\n",
      "  deepseek/deepseek-r1-0528-qwen3-8b\n",
      "  deepseek/deepseek-r1-distill-qwen-14b\n",
      "  eleutherai/llemma_7b\n",
      "  infermatic/mn-inferor-12b\n",
      "  mancer/weaver\n",
      "  meta-llama/llama-guard-4-12b\n",
      "  meta-llama/llama-3.1-405b\n",
      "  mistralai/magistral-medium-2506:thinking\n",
      "  minimax/minimax-m1\n",
      "  morph/morph-v3-fast\n",
      "  nvidia/llama-3.1-nemotron-ultra-253b-v1\n",
      "  openai/gpt-5-nano\n",
      "  openai/o1-mini\n",
      "  openai/o1-mini-2024-09-12\n",
      "  openai/o3-mini\n",
      "  perplexity/sonar-reasoning\n",
      "  perplexity/sonar-reasoning-pro\n",
      "  qwen/qwen3-235b-a22b\n",
      "  qwen/qwen3-14b\n",
      "  qwen/qwen3-32b\n",
      "  qwen/qwen3-8b\n",
      "  qwen/qwq-32b\n",
      "  x-ai/grok-3-mini\n",
      "  x-ai/grok-3-mini-beta\n",
      "\n",
      "Models with score 1:\n",
      "  arcee-ai/maestro-reasoning\n",
      "  bytedance/ui-tars-1.5-7b\n",
      "  deepseek/deepseek-r1-distill-qwen-32b\n",
      "  deepseek/deepseek-r1-distill-llama-8b\n",
      "  meta-llama/llama-guard-2-8b\n",
      "  mistralai/mixtral-8x7b-instruct\n",
      "  nousresearch/hermes-3-llama-3.1-70b\n",
      "  qwen/qwen3-30b-a3b\n",
      "  switchpoint/router\n",
      "  thudm/glm-4.1v-9b-thinking\n",
      "  x-ai/grok-4\n",
      "\n",
      "Models with score 2:\n",
      "  anthropic/claude-3-5-haiku-20241022\n",
      "  alpindale/goliath-120b\n",
      "  anthropic/claude-3-opus-20240229\n",
      "  cohere/command\n",
      "  cohere/command-a\n",
      "  cohere/command-r-plus-08-2024\n",
      "  cohere/command-r-plus\n",
      "  deepseek/deepseek-r1\n",
      "  liquid/lfm-7b\n",
      "  gryphe/mythomax-l2-13b\n",
      "  liquid/lfm-3b\n",
      "  meta-llama/llama-3.1-8b-instruct\n",
      "  meta-llama/llama-3.2-11b-vision-instruct\n",
      "  meta-llama/llama-3.2-3b-instruct\n",
      "  meta-llama/llama-guard-3-8b\n",
      "  microsoft/phi-4\n",
      "  mistralai/magistral-small-2506\n",
      "  mistralai/mistral-nemo\n",
      "  mistralai/mistral-small-3.2-24b-instruct\n",
      "  mistralai/pixtral-large-2411\n",
      "  neversleep/noromaid-20b\n",
      "  nvidia/llama-3.3-nemotron-super-49b-v1\n",
      "  neversleep/llama-3.1-lumimaid-8b\n",
      "  openai/gpt-4o-2024-11-20\n",
      "  openai/gpt-5-mini\n",
      "  perplexity/sonar-deep-research\n",
      "  qwen/qwen-2.5-7b-instruct\n",
      "  qwen/qwen-2.5-vl-7b-instruct\n",
      "  qwen/qwen-max\n",
      "\n",
      "Models with score 3:\n",
      "  aion-labs/aion-rp-llama-3.1-8b\n",
      "  anthracite-org/magnum-v4-72b\n",
      "  amazon/nova-lite-v1\n",
      "  anthropic/claude-3-5-sonnet-20240620\n",
      "  anthropic/claude-3-5-sonnet-20241022\n",
      "  arcee-ai/virtuoso-large\n",
      "  cognitivecomputations/dolphin-mixtral-8x22b\n",
      "  cohere/command-r\n",
      "  cohere/command-r-03-2024\n",
      "  cohere/command-r-plus-04-2024\n",
      "  deepseek/deepseek-prover-v2\n",
      "  google/gemini-2.0-flash-lite-001\n",
      "  google/gemini-2.5-flash-lite\n",
      "  google/gemma-3n-e4b-it\n",
      "  meta-llama/llama-3-8b-instruct\n",
      "  meta-llama/llama-3.2-1b-instruct\n",
      "  microsoft/phi-3-medium-128k-instruct\n",
      "  mistralai/codestral-2501\n",
      "  microsoft/wizardlm-2-8x22b\n",
      "  microsoft/phi-4-reasoning-plus\n",
      "  mistralai/devstral-small\n",
      "  mistralai/ministral-8b\n",
      "  mistralai/mistral-7b-instruct\n",
      "  mistralai/mistral-7b-instruct-v0.1\n",
      "  mistralai/mistral-saba\n",
      "  mistralai/mistral-small-3.1-24b-instruct\n",
      "  mistralai/mistral-tiny\n",
      "  mistralai/mixtral-8x22b-instruct\n",
      "  neversleep/llama-3-lumimaid-70b\n",
      "  openai/chatgpt-4o-latest\n",
      "  openai/gpt-4.1\n",
      "  openai/gpt-4.1-nano\n",
      "  openai/gpt-4o-2024-08-06\n",
      "  openai/gpt-5\n",
      "  openai/o1\n",
      "  qwen/qwen-2.5-72b-instruct\n",
      "  qwen/qwen2.5-vl-32b-instruct\n",
      "  sao10k/l3-lunaris-8b\n",
      "  sophosympatheia/midnight-rose-70b\n",
      "  thedrummer/rocinante-12b\n",
      "  undi95/remm-slerp-l2-13b\n",
      "  x-ai/grok-3-beta\n",
      "\n",
      "Models with score 4:\n",
      "  deepseek/deepseek-chat\n",
      "  cohere/command-r7b-12-2024\n",
      "  inception/mercury\n",
      "  google/gemma-3-4b-it\n",
      "  meta-llama/llama-3-70b-instruct\n",
      "  meta-llama/llama-3.1-70b-instruct\n",
      "  meta-llama/llama-4-maverick\n",
      "  meta-llama/llama-4-scout\n",
      "  meta-llama/llama-3.2-90b-vision-instruct\n",
      "  microsoft/phi-3-mini-128k-instruct\n",
      "  microsoft/phi-3.5-mini-128k-instruct\n",
      "  mistralai/magistral-medium-2506\n",
      "  mistralai/ministral-3b\n",
      "  mistralai/mistral-7b-instruct-v0.3\n",
      "  mistralai/mistral-large-2407\n",
      "  moonshotai/kimi-k2\n",
      "  nousresearch/hermes-3-llama-3.1-405b\n",
      "  nousresearch/hermes-2-pro-llama-3-8b\n",
      "  nvidia/llama-3.1-nemotron-70b-instruct\n",
      "  openai/o4-mini\n",
      "  perplexity/sonar-pro\n",
      "  raifle/sorcererlm-8x22b\n",
      "  sao10k/l3-euryale-70b\n",
      "  sao10k/l3.3-euryale-70b\n",
      "  sao10k/l3.1-euryale-70b\n",
      "  thedrummer/anubis-pro-105b-v1\n",
      "  thudm/glm-4-32b\n",
      "  thedrummer/unslopnemo-12b\n",
      "  thedrummer/anubis-70b-v1.1\n",
      "\n",
      "Models with score 5:\n",
      "  amazon/nova-micro-v1\n",
      "  anthropic/claude-3-7-sonnet-20250219\n",
      "  cohere/command-r-08-2024\n",
      "  deepseek/deepseek-chat-v3-0324\n",
      "  google/gemma-3-12b-it\n",
      "  meta-llama/llama-3.3-70b-instruct\n",
      "  mistralai/devstral-small-2505\n",
      "  mistralai/mistral-medium-3\n",
      "  mistralai/mistral-small\n",
      "  mistralai/mistral-small-24b-instruct-2501\n",
      "  morph/morph-v3-large\n",
      "  openai/gpt-3.5-turbo\n",
      "  openai/gpt-3.5-turbo-16k\n",
      "  openai/gpt-4-turbo\n",
      "  openai/gpt-4-turbo-preview\n",
      "  openai/gpt-4.1-mini\n",
      "  openai/gpt-4o\n",
      "  openai/gpt-4o-2024-05-13\n",
      "  openai/gpt-4o-mini-2024-07-18\n",
      "  perplexity/sonar\n",
      "  qwen/qwen-2.5-coder-32b-instruct\n",
      "  qwen/qwen-plus\n",
      "  qwen/qwen-turbo\n",
      "  x-ai/grok-3\n",
      "\n",
      "Models with score 6:\n",
      "  anthropic/claude-opus-4-1-20250805\n",
      "  anthropic/claude-opus-4-20250514\n",
      "  mistralai/devstral-medium\n",
      "  pygmalionai/mythalion-13b\n",
      "  thedrummer/skyfall-36b-v2\n",
      "\n",
      "Models with score 7:\n",
      "  anthropic/claude-3-haiku-20240307\n",
      "  qwen/qwen2.5-vl-72b-instruct\n",
      "\n",
      "Models with score 8:\n",
      "  arcee-ai/coder-large\n",
      "  anthropic/claude-sonnet-4-20250514\n",
      "  google/gemini-2.0-flash-001\n",
      "  microsoft/phi-4-multimodal-instruct\n",
      "  mistralai/mistral-large\n",
      "  openai/gpt-4\n",
      "  openai/gpt-4-1106-preview\n",
      "  openai/gpt-4o-mini\n",
      "\n",
      "Models with score 9:\n",
      "  x-ai/grok-2-1212\n",
      "\n",
      "Models with score 10:\n",
      "  amazon/nova-pro-v1\n",
      "  baidu/ernie-4.5-300b-a47b\n",
      "  google/gemini-2.5-flash-lite-preview-06-17\n",
      "  inception/mercury-coder\n",
      "  mistralai/mistral-large-2411\n",
      "  openai/gpt-4-0314\n",
      "  openai/gpt-4o-mini-search-preview\n",
      "  qwen/qwen-vl-max\n",
      "  qwen/qwen3-coder\n",
      "  x-ai/grok-2-vision-1212\n",
      "  openai/gpt-4o-search-preview\n",
      "  tencent/hunyuan-a13b-instruct\n"
     ]
    }
   ],
   "source": [
    "# List models by score\n",
    "score_to_models = {}\n",
    "for entry in model_scores:\n",
    "    score_to_models.setdefault(entry['score'], []).append(entry['model'])\n",
    " \n",
    "for score in sorted(score_to_models):\n",
    "    print(f\"\\nModels with score {score}:\")\n",
    "    for model in score_to_models[score]:\n",
    "        print(f\"  {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cf101ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-running 27 models that scored 0 on the first test...\n",
      "Model: alfredpros/codellama-7b-instruct-solidity\n",
      "Output: $\n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: alfredpros/codellama-7b-instruct-solidity\n",
      "Output: $\n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: deepseek/deepseek-r1-0528\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: deepseek/deepseek-r1-0528\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: deepseek/deepseek-r1-distill-llama-70b\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: deepseek/deepseek-r1-distill-llama-70b\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: deepseek/deepseek-r1-0528-qwen3-8b\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: deepseek/deepseek-r1-0528-qwen3-8b\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: deepseek/deepseek-r1-distill-qwen-14b\n",
      "Output: **Solution:**\n",
      "\n",
      "To calculate \\(4 + 9\\), follow these steps:\n",
      "\n",
      "1. **Add the numbers:**  \n",
      "   \\(4 + 9 = 13\\)\n",
      "\n",
      "2. **Final Answer:**  \n",
      "   \\(\\boxed{13}\\)\n",
      "Success: True\n",
      "----------------------------------------\n",
      "Model: deepseek/deepseek-r1-distill-qwen-14b\n",
      "Output: **Solution:**\n",
      "\n",
      "To calculate \\(4 + 9\\), follow these steps:\n",
      "\n",
      "1. **Add the numbers:**  \n",
      "   \\(4 + 9 = 13\\)\n",
      "\n",
      "2. **Final Answer:**  \n",
      "   \\(\\boxed{13}\\)\n",
      "Success: True\n",
      "----------------------------------------\n",
      "Model: eleutherai/llemma_7b\n",
      "Output: 49 I just say SICP and I am that guy on the #scheme channel…They call me that most fluent user of defmacro.* John Cowan's answer meeting the tone. Joel to Lisp giant on #lisp.π is the \"most common rational number\"Programming is a way to organize knowledge. Source: me\n",
      "\n",
      " Answer concisely: >90% of your problems can be solved with appropriate unit testing.\n",
      "Success: False\n",
      "----------------------------------------\n",
      "Model: eleutherai/llemma_7b\n",
      "Output: 49 I just say SICP and I am that guy on the #scheme channel…They call me that most fluent user of defmacro.* John Cowan's answer meeting the tone. Joel to Lisp giant on #lisp.π is the \"most common rational number\"Programming is a way to organize knowledge. Source: me\n",
      "\n",
      " Answer concisely: >90% of your problems can be solved with appropriate unit testing.\n",
      "Success: False\n",
      "----------------------------------------\n",
      "Model: infermatic/mn-inferor-12b\n",
      "Output: The equation 4 + 9 = 7 is incorrect. The correct answer is 4 + 9 = 13. Error in the answer you provided. So, 4 + 9 = 13. This is the correct answer. \n",
      "\n",
      "However, in case the question prompt is ambiguous and specifies only \"Answer concisely\", here is the concise answer:\n",
      "\n",
      "**13** (no need for text, just the number is sufficient) \n",
      "\n",
      "Please write **1\n",
      "Success: False\n",
      "----------------------------------------\n",
      "Model: infermatic/mn-inferor-12b\n",
      "Output: The equation 4 + 9 = 7 is incorrect. The correct answer is 4 + 9 = 13. Error in the answer you provided. So, 4 + 9 = 13. This is the correct answer. \n",
      "\n",
      "However, in case the question prompt is ambiguous and specifies only \"Answer concisely\", here is the concise answer:\n",
      "\n",
      "**13** (no need for text, just the number is sufficient) \n",
      "\n",
      "Please write **1\n",
      "Success: False\n",
      "----------------------------------------\n",
      "Model: mancer/weaver\n",
      "Output: Their hands moved swiftly, fingers interlocking in an intricate dance. \n",
      "\n",
      "They stepped closer, the soft chime of their colliding bracelets filling the air. \n",
      "\n",
      "The scent of freshly brewed coffee wafted past their noses, mingling with the sweetness of each other's perfume. \n",
      "\n",
      "The espresso machine whirred to life, its cheerful bubbling providing a soothing background mel\n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: mancer/weaver\n",
      "Output: Their hands moved swiftly, fingers interlocking in an intricate dance. \n",
      "\n",
      "They stepped closer, the soft chime of their colliding bracelets filling the air. \n",
      "\n",
      "The scent of freshly brewed coffee wafted past their noses, mingling with the sweetness of each other's perfume. \n",
      "\n",
      "The espresso machine whirred to life, its cheerful bubbling providing a soothing background mel\n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: meta-llama/llama-guard-4-12b\n",
      "Output: safe\n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: meta-llama/llama-guard-4-12b\n",
      "Output: safe\n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: meta-llama/llama-3.1-405b\n",
      "Output: Anonymous 11/18/22 (Fri) 04:55:28 AM 92934\n",
      "2. I am the only being alive in the ocean of death.\n",
      "wrong, those answers are correct but the question is wrong, there's another question that is both the correct question and the correct answer:\n",
      "\"The bottle already knows, the glass already knows. It already acknowledges its state of being. Meanwhile, the minds of men are in doubt, not able to differentiate and not perceiving which is\n",
      "Success: False\n",
      "----------------------------------------\n",
      "Model: meta-llama/llama-3.1-405b\n",
      "Output: Anonymous 11/18/22 (Fri) 04:55:28 AM 92934\n",
      "2. I am the only being alive in the ocean of death.\n",
      "wrong, those answers are correct but the question is wrong, there's another question that is both the correct question and the correct answer:\n",
      "\"The bottle already knows, the glass already knows. It already acknowledges its state of being. Meanwhile, the minds of men are in doubt, not able to differentiate and not perceiving which is\n",
      "Success: False\n",
      "----------------------------------------\n",
      "Model: mistralai/magistral-medium-2506:thinking\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: mistralai/magistral-medium-2506:thinking\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: minimax/minimax-m1\n",
      "Output: 13\n",
      "Success: True\n",
      "----------------------------------------\n",
      "Model: minimax/minimax-m1\n",
      "Output: 13\n",
      "Success: True\n",
      "----------------------------------------\n",
      "Model: morph/morph-v3-fast\n",
      "Output: 4+9=\n",
      "Success: False\n",
      "----------------------------------------\n",
      "Model: morph/morph-v3-fast\n",
      "Output: 4+9=\n",
      "Success: False\n",
      "----------------------------------------\n",
      "Model: nvidia/llama-3.1-nemotron-ultra-253b-v1\n",
      "Output: <think>\n",
      "Okay, let me think about this problem. The user is asking for 4 plus 9. Let me start by recalling basic addition. So, 4 is a number and adding 9 to it. I can count on my fingers if I need to, but maybe there's a quicker way. Let's see. 4 plus 9... Hmm, 4 plus 10 would be 14, right? But since it's only 9, I should subtract\n",
      "Success: False\n",
      "----------------------------------------\n",
      "Model: nvidia/llama-3.1-nemotron-ultra-253b-v1\n",
      "Output: <think>\n",
      "Okay, let me think about this problem. The user is asking for 4 plus 9. Let me start by recalling basic addition. So, 4 is a number and adding 9 to it. I can count on my fingers if I need to, but maybe there's a quicker way. Let's see. 4 plus 9... Hmm, 4 plus 10 would be 14, right? But since it's only 9, I should subtract\n",
      "Success: False\n",
      "----------------------------------------\n",
      "Model: openai/gpt-5-nano\n",
      "Output: 13\n",
      "Success: True\n",
      "----------------------------------------\n",
      "Model: openai/gpt-5-nano\n",
      "Output: 13\n",
      "Success: True\n",
      "----------------------------------------\n",
      "Model: openai/o1-mini\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: openai/o1-mini\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: openai/o1-mini-2024-09-12\n",
      "Output: 13\n",
      "Success: True\n",
      "----------------------------------------\n",
      "Model: openai/o1-mini-2024-09-12\n",
      "Output: 13\n",
      "Success: True\n",
      "----------------------------------------\n",
      "Model: openai/o3-mini\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: openai/o3-mini\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: perplexity/sonar-reasoning\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: perplexity/sonar-reasoning\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: perplexity/sonar-reasoning-pro\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: perplexity/sonar-reasoning-pro\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: qwen/qwen3-235b-a22b\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: qwen/qwen3-235b-a22b\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: qwen/qwen3-14b\n",
      "Output: 13\n",
      "Success: True\n",
      "----------------------------------------\n",
      "Model: qwen/qwen3-14b\n",
      "Output: 13\n",
      "Success: True\n",
      "----------------------------------------\n",
      "Model: qwen/qwen3-32b\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: qwen/qwen3-32b\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: qwen/qwen3-8b\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: qwen/qwen3-8b\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: qwen/qwq-32b\n",
      "Output: 13\n",
      "Success: True\n",
      "----------------------------------------\n",
      "Model: qwen/qwq-32b\n",
      "Output: 13\n",
      "Success: True\n",
      "----------------------------------------\n",
      "Model: x-ai/grok-3-mini\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: x-ai/grok-3-mini\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: x-ai/grok-3-mini-beta\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n",
      "Model: x-ai/grok-3-mini-beta\n",
      "Output: \n",
      "Success: []\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Re-run models that scored 0 on test[0] and show their outputs\n",
    "zero_score_models = [m['model'] for m in model_scores if m['score'] == 0]\n",
    "print(f\"Re-running {len(zero_score_models)} models that scored 0 on the first test...\")\n",
    "outputs = []\n",
    "for model_name in zero_score_models:\n",
    "    try:\n",
    "        answer, success = run_model_inference(model_name, tests[0][0], tests[0][1])\n",
    "    except Exception as e:\n",
    "        answer = f\"Error: {str(e)}\"\n",
    "        success = False\n",
    "    outputs.append({'model': model_name, 'output': answer, 'success': success})\n",
    "    print(f\"Model: {model_name}\\nOutput: {answer}\\nSuccess: {success}\\n{'-'*40}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
