{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG2gZSoSJD5C"
      },
      "source": [
        "# Verified Integer Arithmetic in Transformers - Training Graphs\n",
        "\n",
        "This Colab graphs training data across multiple models.\n",
        "\n",
        "This Colab follows on from https://github.com/PhilipQuirke/quanta_addition_and_subtraction/blob/main/notebooks/VerifiedArithmeticTrain.ipynb which trained the models, and outputs model_name.pth and model_name_train.json\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzkGrSqHJKqN"
      },
      "source": [
        "## Tips for using the Colab\n",
        " * You can run and alter the code in this CoLab notebook yourself in Google CoLab ( https://colab.research.google.com/ ).\n",
        " * To run the notebook, in Google CoLab, **you will need to** go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.\n",
        " * Some graphs are interactive!\n",
        " * Use the table of contents pane in the sidebar to navigate.\n",
        " * Collapse irrelevant sections with the dropdown arrows.\n",
        " * Search the page using the search in the sidebar, not CTRL+F."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTd3nmsMJV5T"
      },
      "source": [
        "# Part 0: Import libraries\n",
        "Imports standard libraries.\n",
        "\n",
        "Imports \"verified_transformer\" public library as \"qt\". This library is specific to this CoLab's \"QuantaTool\" approach to transformer analysis. Refer to [README.md](https://github.com/PhilipQuirke/verified_transformers/blob/main/README.md) for more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCdmr6-_Jkzi",
        "outputId": "6e6fc40c-1223-489c-b1a3-9a4670f64744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.10/dist-packages (0.2.1)\n"
          ]
        }
      ],
      "source": [
        "DEVELOPMENT_MODE = True\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "    !pip install matplotlib\n",
        "\n",
        "    !pip install kaleido\n",
        "    !pip install transformer_lens\n",
        "    !pip install torchtyping\n",
        "    !pip install transformers\n",
        "\n",
        "    !pip install numpy\n",
        "    !pip install scikit-learn\n",
        "\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "    def setup_jupyter(install_libraries=False):\n",
        "        if install_libraries:\n",
        "            !pip install matplotlib==3.8.4\n",
        "            !pip install kaleido==0.2.1\n",
        "            !pip install transformer_lens==1.15.0\n",
        "            !pip install torchtyping==0.1.4\n",
        "            !pip install transformers==4.39.3\n",
        "\n",
        "            !pip install numpy==1.26.4\n",
        "            !pip install plotly==5.20.0\n",
        "            !pip install pytest==8.1.1\n",
        "            !pip install scikit-learn==1.4.1.post1\n",
        "\n",
        "        print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "        from IPython import get_ipython\n",
        "\n",
        "        ipython = get_ipython()\n",
        "        # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "        ipython.magic(\"load_ext autoreload\")\n",
        "        ipython.magic(\"autoreload 2\")\n",
        "\n",
        "    # setup_jupyter(install_libraries=True)   # Uncomment if you need to install libraries in notebook.\n",
        "    setup_jupyter(install_libraries=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Up2QLAZLJnG9"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import kaleido\n",
        "import plotly.io as pio\n",
        "\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve-TndERJoaJ"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6zOEFryJqGN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6TE7A9SxySA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOh-m1lO4hrO"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-optimize\n",
        "\n",
        "import re\n",
        "import sklearn # Aka scikit.learn\n",
        "import skopt # Aka scikit.optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8VQ4e0QJsIB"
      },
      "outputs": [],
      "source": [
        "import transformer_lens\n",
        "from transformer_lens.utils import download_file_from_hf\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2P3cndolKDM"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade git+https://github.com/PhilipQuirke/quanta_mech_interp.git\n",
        "import quanta_tools as qt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade git+https://github.com/PhilipQuirke/quanta_addition_subtraction.git\n",
        "import maths_tools as mt"
      ],
      "metadata": {
        "id": "hpMNAVSlO5YX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldGPkaokJQM5"
      },
      "source": [
        "# Part 1A: Configuration\n",
        "\n",
        "Which existing model do we want to graph?\n",
        "\n",
        "The existing model weightings created by the sister Colab [VerifiedArithmeticTrain](https://github.com/PhilipQuirke/transformer-maths/blob/main/assets/VerifiedArithmeticTrain.ipynb) are loaded from HuggingFace (in Part 5). Refer https://github.com/PhilipQuirke/quanta_addition_and_subtraction/blob/main/README.md for more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1DXZQ2E6yAi"
      },
      "outputs": [],
      "source": [
        "# Singleton QuantaTool \"main\" configuration class. MathsConfig is derived from the chain AlgoConfig > UsefulConfig > ModelConfig\n",
        "cfg = mt.MathsConfig()\n",
        "\n",
        "\n",
        "# Which model do we want to graph? Uncomment one line:\n",
        "\n",
        "# Addition models\n",
        "#cfg.set_model_names( \"add_d5_l1_h3_t15K_s372001\" )  # AddAccuracy=Two9s. Inaccurate as only has one layer. Can predict S0, S1 and S2 complexity questions.\n",
        "#cfg.set_model_names( \"add_d5_l2_h3_t15K_s372001\" )  # AddAccuracy=Six9s. AvgFinalLoss=1.6e-08\n",
        "#cfg.set_model_names( \"add_d5_l2_h3_t40K_s372001\" )  # AddAccuracy=Six9s. AvgFinalLoss=2e-09. Fewest nodes\n",
        "#cfg.set_model_names( \"add_d6_l2_h3_t15K_s372001\" )  # AddAccuracy=Fives. AvgFinalLoss=1.7e-08. (2/M fail: 018539+789353=+0807892 ModelAnswer: +0707892, 747332+057349=+0804681 ModelAnswer: +0704681)\n",
        "#cfg.set_model_names( \"add_d6_l2_h3_t20K_s173289\" )  # AddAccuracy=Six9s. AvgFinalLoss=1.5e-08. Fewest nodes\n",
        "#cfg.set_model_names( \"add_d6_l2_h3_t20K_s572091\" )  # AddAccuracy=Six9s. AvgFinalLoss=7e-09\n",
        "#cfg.set_model_names( \"add_d6_l2_h3_t40K_s372001\" )  # AddAccuracy=Six9s. AvgFinalLoss=2e-09\n",
        "#cfg.set_model_names( \"add_d7_l2_h3_t45K_s173289\" )  # AddAccuracy=Six9s. AvgFinalLoss=3e-09. (0/M fail)\n",
        "#cfg.set_model_names( \"add_d8_l2_h3_t45K_s173289\" )  # AddAccuracy=Six9s. AvgFinalLoss=3e-09. (0/M fail)\n",
        "#cfg.set_model_names( \"add_d9_l2_h3_t45K_s173289\" )  # AddAccuracy=Six9s. AvgFinalLoss=3e-09. (0/M fail)\n",
        "#cfg.set_model_names( \"add_d10_l2_h3_t40K_s572091\" ) # AddAccuracy=Six9s. AvgFinalLoss=7e-09. (1/M fail: 0000000555+0000000445=+00000001000 ModelAnswer: +00000000900)\n",
        "#cfg.set_model_names( \"add_d10_l2_h3_t40K_gf_s572091\" ) # AddAccuracy=Six9s. AvgFinalLoss=3.5-09. GrokFast.\n",
        "#cfg.set_model_names( \"add_d11_l2_h3_t50K_s572091\" )  # AddAccuracy=Five9s. AvgFinalLoss=8e-09. (2/M fail)\n",
        "#cfg.set_model_names( \"add_d12_l2_h3_t50K_s572091\" )  # AddAccuracy=Five9s. AvgFinalLoss=5e-09. (3/M fail)\n",
        "#cfg.set_model_names( \"add_d13_l2_h3_t50K_s572091\" )  # AddAccuracy=Six9s. AvgFinalLoss=6.3e-08. (1/M fail)\n",
        "cfg.set_model_names( \"add_d14_l2_h3_t60K_s572091\" )  # AddAccuracy=Three9S. AvgFinalLoss=5.6e-06. (199/M fail)\n",
        "#cfg.set_model_names( \"add_d15_l2_h3_t80K_s572091\" ) # AddAccuracy=Five9s. AvgFinalLoss=8.6e-08 (10/M fail)\n",
        "#cfg.set_model_names( \"add_d20_l2_h3_t80K_s572091\" ) # AddAccuracy=Poor! AvgFinalLoss=0.20!\n",
        "\n",
        "# Subtraction model\n",
        "#cfg.set_model_names( \"sub_d6_l2_h3_t30K_s372001\" )  # SubAccuracy=Six9s. AvgFinalLoss=5.8e-06\n",
        "#cfg.set_model_names( \"sub_d10_l2_h3_t75K_s173289\" )  # SubAccuracy=Two9s. (6672/M fails) AvgFinalLoss=0.002002.\n",
        "#cfg.set_model_names( \"sub_d10_l2_h3_t75K_gf_s173289\" )  # SubAccuracy=Two9s. GrokFast. (5246/M fails) AvgFinalLoss=0.001197\n",
        "\n",
        "# Mixed (addition and subtraction) model\n",
        "#cfg.set_model_names( \"mix_d6_l3_h4_t40K_s372001\" )  # Add/SubAccuracy=Six9s/Six9s. AvgFinalLoss=5e-09. (1/M fail: 463687+166096=+0629783 ModelAnswer: +0639783)\n",
        "#cfg.set_model_names( \"mix_d10_l3_h4_t75K_s173289\" )  # Add/SubAccuracy=Five9s/Two9s. AvgFinalLoss=1.125e-06 (2/M fail: 3301956441+6198944455=+09500900896 ModelAnswer: +09500800896) (295/M fail: 8531063649-0531031548=+08000032101 ModelAnswer: +07900032101)\n",
        "#cfg.set_model_names( \"mix_d10_l3_h4_t75K_gf_s173289\" )  # Add/SubAccuracy=Six9s/Three9s. GrokFast. AvgFinalLoss 8.85e-07 (1/M fail) (294/M fail)\n",
        "\n",
        "# Mixed models initialized with addition model\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l2_h3_t40K_s572091\" )  # Add/SubAccuracy=Six9s/Five9s. AvgLoss = 2.4e-08 (5/M fails e.g. 565000-364538=+0200462 ModelAnswer: +0100462)\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l3_h3_t40K_s572091\" )  # Add/SubAccuracy=Six9s/Five9s. AvgFinalLoss=1.8e-08. (3/M fails e.g. 072074-272074=-0200000 ModelAnswer: +0200000)\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l3_h3_t80K_s572091\" )  # Add/SubAccuracy=Six9s/Five9s AvgLoss = 1.6e-08 (3/M fails e.g. 229672-229678=-0000006 ModelAnswer: +0000006) (EnrichFalse => 0/M, 4/M)\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l3_h4_t40K_s372001\" )  # Add/SubAccuracy=Six9s/Six9s. AvgFinalLoss=8e-09. MAIN FOCUS\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l3_h4_t40K_s173289\" )  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss=1.4e-08. (3/M fails e.g. 850038+159060=+1009098 ModelAnswer: +0009098) (2/M fails e.g. 77285-477285=+0100000 Q: ModelAnswer: +0000000) (EnrichFalse => 0/M, 3/M)\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l3_h4_t50K_s572091\" )  # Add/SubAccuracy=Six9s/Five9s. AvgFinalLoss=2.9e-08. (4/M fails e.g. 986887-286887=+0700000 ModelAnswer: +0600000) (EnrichFalse => 0/M, 3/M)\n",
        "#cfg.set_model_names( \"ins1_mix_d10_l3_h3_t50K_s572091\" )  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss 6.3e-07  (6/M fails e.g. 5068283822+4931712829=+09999996651 ModelAnswer: +19099996651) (7/M fails e.g. 3761900218-0761808615=+03000091603 ModelAnswer: +02000091603)\n",
        "#cfg.set_model_names( \"ins1_mix_d10_l3_h3_t50K_gf_s572091\" ) # Add/SubAccuracy=Five9s/Two9s. GrokFast. AvgFinalLoss=4.0e-06 (2/M fails) (1196/M fails)\n",
        "\n",
        "# Mixed model initialized with addition model. Reset useful heads every 100 epochs.\n",
        "#cfg.set_model_names( \"ins2_mix_d6_l4_h4_t40K_s372001\" )  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss=1.7e-08. (3/M fails e.g. 530757+460849=+0991606 ModelAnswer: +0091606) (8 fails e.g. 261926-161857=+0100069 ModelAnswer: +0000069)\n",
        "\n",
        "# Mixed model initialized with addition model. Reset useful heads & MLPs every 100 epochs.\n",
        "#cfg.set_model_names( \"ins3_mix_d6_l4_h3_t40K_s372001\" )  # Add/SubAccuracy=Four9s/Two9s. AvgFinalLoss=3.0e-04. (17/M fails e.g. 273257+056745=+0330002 ModelAnswer: +0320002) (3120 fails e,g. 09075-212133=-0003058 ModelAnswer: +0003058)\n",
        "\n",
        "# Addition&Subtraction model initialized with addition model. Reset useful heads & MLPs every epoch\n",
        "#cfg.set_model_names( \"ins4_mix_d6_l4_h3_t40K_s372001\" )  # AvgFinalLoss 4.7e-06\n",
        "\n",
        "# Mixed models initialized with addition model. Insert mode 5\n",
        "#cfg.set_model_names( \"ins5_mix_d6_l3_h4_t30K_s775824\" )  # Add/SubAccuracy=???/??? TODO\n",
        "#cfg.set_model_names( \"ins5_mix_d6_l2_h4_t30K_s775824\" )  # Add/SubAccuracy=???/??? TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_IIpX2H2tNe"
      },
      "source": [
        "# Part 1B: Configuration: Input and Output file names\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0DJkn5l2gq3"
      },
      "outputs": [],
      "source": [
        "main_fname_pth = cfg.model_name + '.pth'\n",
        "main_fname_train_json = cfg.model_name + '_train.json'\n",
        "main_fname_behavior_json = cfg.model_name + '_behavior.json'\n",
        "main_fname_maths_json = cfg.model_name + '_maths.json'\n",
        "main_repo_name=\"PhilipQuirke/VerifiedArithmetic\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfdCBTuqh4zq"
      },
      "outputs": [],
      "source": [
        "# Update \"cfg\" with additional training config (including cfg.insert_*) with information stored in:\n",
        "#      https://huggingface.co/PhilipQuirke/VerifiedArithmetic/raw/main/ins1_mix_d6_l3_h4_t40K_s372001_train.json\"\n",
        "training_data_json = qt.download_huggingface_json(main_repo_name, main_fname_train_json)\n",
        "training_loss_list = qt.load_training_json(cfg, training_data_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f48_G6wr730Q"
      },
      "outputs": [],
      "source": [
        "print('Main model will be read from HuggingFace file', main_repo_name, main_fname_pth)\n",
        "print('Main model training config / loss will be read from HuggingFace file', main_fname_train_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keTceF_3zbVP"
      },
      "source": [
        "# Part 2: Single model training loss graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCwcStUps62W"
      },
      "outputs": [],
      "source": [
        "print(\"%Add=\", cfg.perc_add, \"%Sub=\", cfg.perc_sub, \"%Mult=\", cfg.perc_mult, \"InsertMode=\", cfg.insert_mode, \"File=\", cfg.model_name)\n",
        "print(\"weight_decay=\", cfg.weight_decay, \"lr=\", cfg.lr, \"batch_size=\", cfg.batch_size)\n",
        "print( \"Avg loss over last 5 epochs (AvgFinalLoss)\", cfg.avg_final_loss)\n",
        "print( \"Final epoch loss\", cfg.final_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYV9FWt3zfFw"
      },
      "outputs": [],
      "source": [
        "# Show the model final training loss and graph loss over epochs\n",
        "if training_loss_list:\n",
        "  answer_digits = cfg.n_digits + 1\n",
        "  title_font_size=32\n",
        "  tick_font_size=24\n",
        "\n",
        "  qt.plot_loss_lines(cfg, 1500, [training_loss_list[:1500]], labels = ['All'], log_y=False,\n",
        "                       title='Training Loss', title_font_size=title_font_size, tick_font_size=tick_font_size)\n",
        "\n",
        "  full_title, fig = qt.plot_loss_lines(cfg, cfg.n_training_steps, [training_loss_list], labels = ['All'], log_y=True,\n",
        "                       title='Training Loss', title_font_size=title_font_size, tick_font_size=tick_font_size)\n",
        "  pio.write_image(fig, cfg.model_name + '_LogTrainingLoss.' + cfg.graph_file_suffix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sWq2xyVUzOJ"
      },
      "source": [
        "# Part 3: Multiple Addition model training loss graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqQZ3NJgalVj"
      },
      "outputs": [],
      "source": [
        "json_file_paths = [\n",
        "    \"add_d5_l2_h3_t40K_s372001\",\n",
        "    \"add_d6_l2_h3_t40K_s372001\",\n",
        "    \"add_d7_l2_h3_t45K_s173289\",\n",
        "    \"add_d8_l2_h3_t45K_s173289\",\n",
        "    \"add_d9_l2_h3_t45K_s173289\",\n",
        "    \"add_d10_l2_h3_t40K_s572091\",\n",
        "    \"add_d11_l2_h3_t50K_s572091\",\n",
        "    \"add_d12_l2_h3_t50K_s572091\",\n",
        "    \"add_d13_l2_h3_t50K_s572091\",\n",
        "    \"add_d14_l2_h3_t60K_s572091\",\n",
        "    \"add_d15_l2_h3_t80K_s572091\",\n",
        "]\n",
        "\n",
        "all_training_loss_lists = []\n",
        "model_labels = []\n",
        "\n",
        "# Load and process the training loss data from each JSON file\n",
        "for file_path in json_file_paths:\n",
        "    training_data_json = qt.download_huggingface_json(main_repo_name, file_path+\"_train.json\")\n",
        "    training_loss_list = qt.load_training_json(cfg, training_data_json)\n",
        "    all_training_loss_lists.append(training_loss_list)\n",
        "    model_labels.append(file_path.split(\"_\")[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVq8um7Ehues"
      },
      "outputs": [],
      "source": [
        "def smooth_data(data, window_size=500):\n",
        "    \"\"\"Apply rolling statistics to the data\"\"\"\n",
        "    series = pd.Series(data)\n",
        "    smoothed_mean = series.rolling(window=window_size, center=True).mean()\n",
        "    smoothed_min = series.rolling(window=window_size, center=True).min()\n",
        "    smoothed_max = series.rolling(window=window_size, center=True).max()\n",
        "    return smoothed_mean, smoothed_min, smoothed_max\n",
        "\n",
        "def hex_to_rgba(hex_color, alpha=0.2):\n",
        "    \"\"\"Convert hex color to rgba string with alpha\"\"\"\n",
        "    hex_color = hex_color.lstrip('#')\n",
        "    r = int(hex_color[0:2], 16)\n",
        "    g = int(hex_color[2:4], 16)\n",
        "    b = int(hex_color[4:6], 16)\n",
        "    return f'rgba({r},{g},{b},{alpha})'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VI_W6ZDOjaDA"
      },
      "outputs": [],
      "source": [
        "fig = make_subplots(rows=2, cols=1, subplot_titles=(\"Training Loss Comparison (First 15K Steps)\", \"Training Loss Comparison (Log Scale)\"))\n",
        "\n",
        "# Color palette for different traces\n",
        "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#aec7e8']\n",
        "\n",
        "for i, loss_list in enumerate(all_training_loss_lists):\n",
        "    smooth_mean, smooth_min, smooth_max = smooth_data(loss_list)\n",
        "    x_vals = list(range(len(loss_list)))\n",
        "\n",
        "    # Regular scale plot\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=x_vals,\n",
        "            y=smooth_max,\n",
        "            mode='lines',\n",
        "            line=dict(width=0),\n",
        "            showlegend=False,\n",
        "            name=f'{model_labels[i]} Upper Bound'\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=x_vals,\n",
        "            y=smooth_min,\n",
        "            mode='lines',\n",
        "            line=dict(width=0),\n",
        "            fillcolor=hex_to_rgba(colors[i]),\n",
        "            fill='tonexty',\n",
        "            showlegend=False,\n",
        "            name=f'{model_labels[i]} Lower Bound'\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    # Add mean line\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=x_vals,\n",
        "            y=smooth_mean,\n",
        "            mode='lines',\n",
        "            line=dict(color=colors[i], width=2),\n",
        "            name=model_labels[i]\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    # Log scale plot\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=x_vals,\n",
        "            y=smooth_max,\n",
        "            mode='lines',\n",
        "            line=dict(width=0),\n",
        "            showlegend=False,\n",
        "            name=f'{model_labels[i]} Upper Bound'\n",
        "        ),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=x_vals,\n",
        "            y=smooth_min,\n",
        "            mode='lines',\n",
        "            line=dict(width=0),\n",
        "            fillcolor=hex_to_rgba(colors[i]),\n",
        "            fill='tonexty',\n",
        "            showlegend=False,\n",
        "            name=f'{model_labels[i]} Lower Bound'\n",
        "        ),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "    # Add mean line\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=x_vals,\n",
        "            y=smooth_mean,\n",
        "            mode='lines',\n",
        "            line=dict(color=colors[i], width=2),\n",
        "            showlegend=False,\n",
        "            name=model_labels[i]\n",
        "        ),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(\n",
        "    height=1000,\n",
        "    showlegend=True,\n",
        "    legend=dict(\n",
        "        yanchor=\"top\",\n",
        "        y=0.95,\n",
        "        xanchor=\"right\",\n",
        "        x=0.95\n",
        "    ),\n",
        "    template=\"plotly_white\"\n",
        ")\n",
        "\n",
        "# Update axes labels and ranges\n",
        "fig.update_xaxes(title_text=\"Training Step\", row=1, col=1, range=[0, 15000])\n",
        "fig.update_xaxes(title_text=\"Training Step\", row=2, col=1, range=[0, 80000])\n",
        "fig.update_yaxes(title_text=\"Training Loss\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Training Loss (Log Scale)\", type=\"log\", row=2, col=1)\n",
        "\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uG2gZSoSJD5C",
        "pTd3nmsMJV5T",
        "F_IIpX2H2tNe"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}