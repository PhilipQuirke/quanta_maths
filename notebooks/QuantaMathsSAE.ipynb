{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG2gZSoSJD5C"
      },
      "source": [
        "# Quanta Maths: Integer Addition and Subtraction in Transformers - Train an SAE\n",
        "\n",
        "This Colab trains an SAE on a Transformer models to help understand its MLP layer.\n",
        "\n",
        "The models perform integer addition and/or subtraction e.g. 133357+182243=+0315600 and 123450-345670=-0123230. Each digit is a separate token. For 6 digit questions, the model is given 14 \"question\" (input) tokens, and must then predict the corresponding 8 \"answer\" (output) tokens.\n",
        "\n",
        "This Colab follows on from https://github.com/PhilipQuirke/quanta_maths/blob/main/notebooks/QuantaMatthsTrain.ipynb which trained the models, and outputs model.pth and training_loss.json\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzkGrSqHJKqN"
      },
      "source": [
        "## Tips for using the Colab\n",
        " * You can run and alter the code in this CoLab notebook yourself in Google CoLab ( https://colab.research.google.com/ ).\n",
        " * To run the notebook, in Google CoLab, **you will need to** go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.\n",
        " * Some graphs are interactive!\n",
        " * Use the table of contents pane in the sidebar to navigate.\n",
        " * Collapse irrelevant sections with the dropdown arrows.\n",
        " * Search the page using the search in the sidebar, not CTRL+F."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTd3nmsMJV5T"
      },
      "source": [
        "# Part 0: Import libraries\n",
        "Imports standard libraries.\n",
        "\n",
        "Imports \"quanta_maths\" public library as \"mmi\". Refer to [README.md](https://github.com/PhilipQuirke/quanta_maths/blob/main/README.md) for more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCdmr6-_Jkzi"
      },
      "outputs": [],
      "source": [
        "DEVELOPMENT_MODE = True\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "    !pip install matplotlib\n",
        "    !pip install kaleido\n",
        "\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    #!pip install matplotlib==3.8.4\n",
        "    #!pip install kaleido==0.2.1\n",
        "    # Install required libraries if not already installed\n",
        "    import sys\n",
        "    import subprocess\n",
        "    def install(package):\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "    # List of required packages\n",
        "    required_packages = [\"matplotlib\", \"kaleido\", \"plotly\", \"scikit-learn\", \"scikit-optimize\", \"huggingface_hub\", \"torch\", \"numpy\"]\n",
        "    for pkg in required_packages:\n",
        "        try:\n",
        "            __import__(pkg.replace('-', '_'))\n",
        "        except ImportError:\n",
        "            print(f\"Installing {pkg}...\")\n",
        "            install(pkg)\n",
        "\n",
        "    from IPython import get_ipython\n",
        "    ipython = get_ipython()\n",
        "    %load_ext autoreload\n",
        "    %autoreload 2\n",
        "\n",
        "    # Uncomment below to force reinstall if needed\n",
        "    # for pkg in required_packages:\n",
        "    #     install(pkg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA5NlYMu7D0f"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import QuantaMechInterp as qmi\n",
        "except ImportError:\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install --upgrade git+https://github.com/PhilipQuirke/quanta_mech_interp.git\n",
        "    import QuantaMechInterp as qmi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmnVaFTuQXtC"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade git+https://github.com/PhilipQuirke/quanta_maths.git\n",
        "import MathsMechInterp as mmi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Up2QLAZLJnG9"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import kaleido\n",
        "import plotly.io as pio\n",
        "\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve-TndERJoaJ"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6zOEFryJqGN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import itertools\n",
        "import re\n",
        "from enum import Enum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6TE7A9SxySA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8VQ4e0QJsIB"
      },
      "outputs": [],
      "source": [
        "import transformer_lens\n",
        "from transformer_lens.utils import download_file_from_hf\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofc_XqLv6pnL"
      },
      "outputs": [],
      "source": [
        "import sklearn # Aka scikit.learn\n",
        "import skopt # Aka scikit.optimize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldGPkaokJQM5"
      },
      "source": [
        "# Part 1A: Configuration\n",
        "\n",
        "Which existing model do we want to analyze?\n",
        "\n",
        "The existing model weightings created by the sister Colab [QuantaMathsTrain](https://github.com/PhilipQuirke/quanta_maths/blob/main/notebooks/QuantaMathsTrain.ipynb) are loaded from HuggingFace (in Part 5). Refer https://github.com/PhilipQuirke/quanta_maths/blob/main/README.md for more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1DXZQ2E6yAi"
      },
      "outputs": [],
      "source": [
        "# Singleton QuantaTool \"main\" configuration class. MathsConfig is derived from the chain AlgoConfig > UsefulConfig > ModelConfig\n",
        "cfg = mmi.MathsConfig()\n",
        "\n",
        "\n",
        "# Which model do we want to analyze? Uncomment one line:\n",
        "\n",
        "# Addition models\n",
        "#cfg.set_model_names( \"add_d5_l1_h3_t15K_s372001\" )  # AddAccuracy=Two9s. Inaccurate as only has one layer. Reproduces previous paper model.\n",
        "#cfg.set_model_names( \"add_d5_l2_h3_t15K_s372001\" )  # AddAccuracy=Six9s. AvgFinalLoss=1.6e-08\n",
        "#cfg.set_model_names( \"add_d5_l2_h3_t40K_s372001\" )  # AddAccuracy=Six9s. AvgFinalLoss=2e-09. (0/M fail). Fewest nodes\n",
        "#cfg.set_model_names( \"add_d6_l2_h3_t15K_s372001\" )  # AddAccuracy=Fives. AvgFinalLoss=1.7e-08. (2/M fail)\n",
        "#cfg.set_model_names( \"add_d6_l2_h3_t20K_s173289\" )  # AddAccuracy=Six9s. AvgFinalLoss=1.5e-08. (0/M fail). Fewest nodes\n",
        "#cfg.set_model_names( \"add_d6_l2_h3_t20K_s572091\" )  # AddAccuracy=Six9s. AvgFinalLoss=7e-09.  (0/M fail)\n",
        "#cfg.set_model_names( \"add_d6_l2_h3_t40K_s372001\" )  # AddAccuracy=Six9s. AvgFinalLoss=2e-09. (0/M fail)\n",
        "#cfg.set_model_names( \"add_d7_l2_h3_t45K_s173289\" )  # AddAccuracy=Six9s. AvgFinalLoss=3e-09. (0/M fail)\n",
        "#cfg.set_model_names( \"add_d8_l2_h3_t45K_s173289\" )  # AddAccuracy=Six9s. AvgFinalLoss=3e-09. (0/M fail)\n",
        "#cfg.set_model_names( \"add_d9_l2_h3_t45K_s173289\" )  # AddAccuracy=Six9s. AvgFinalLoss=3e-09. (0/M fail)\n",
        "#cfg.set_model_names( \"add_d10_l2_h3_t40K_s572091\" ) # AddAccuracy=Six9s. AvgFinalLoss=7e-09. (1/M fail)\n",
        "#cfg.set_model_names( \"add_d10_l2_h3_t40K_gf_s572091\" ) # AddAccuracy=Six9s. AvgFinalLoss=3.5-09. GrokFast. Minor accuracy improvement\n",
        "#cfg.set_model_names( \"add_d11_l2_h3_t50K_s572091\" )  # AddAccuracy=Five9s. AvgFinalLoss=8e-09. (2/M fail)\n",
        "#cfg.set_model_names( \"add_d12_l2_h3_t50K_s572091\" )  # AddAccuracy=Five9s. AvgFinalLoss=5e-09. (3/M fail)\n",
        "#cfg.set_model_names( \"add_d13_l2_h3_t50K_s572091\" )  # AddAccuracy=Six9s. AvgFinalLoss=6.3e-08. (1/M fail)\n",
        "#cfg.set_model_names( \"add_d14_l2_h3_t60K_s572091\" )  # AddAccuracy=Three9S. AvgFinalLoss=5.6e-06. (199/M fail)\n",
        "#cfg.set_model_names( \"add_d15_l2_h3_t80K_s572091\" ) # AddAccuracy=Five9s. AvgFinalLoss=8.6e-08 (10/M fail)\n",
        "#cfg.set_model_names( \"add_d20_l2_h3_t80K_s572091\" ) # AddAccuracy=Poor! AvgFinalLoss=0.20!\n",
        "\n",
        "# Subtraction model\n",
        "#cfg.set_model_names( \"sub_d6_l2_h3_t30K_s372001\" )  # SubAccuracy=Six9s. AvgFinalLoss=5.8e-06\n",
        "#cfg.set_model_names( \"sub_d10_l2_h3_t75K_s173289\" )  # SubAccuracy=Two9s. AvgFinalLoss=0.002002. (6672/M fails)\n",
        "#cfg.set_model_names( \"sub_d10_l2_h3_t75K_gf_s173289\" )  # SubAccuracy=Two9s. GrokFast. AvgFinalLoss=0.001197. (5246/M fails). Minor accuracy improvement\n",
        "\n",
        "# Mixed (addition and subtraction) model\n",
        "#cfg.set_model_names( \"mix_d5_l3_h4_t40K_s372001\" )  # Add/SubAccuracy=Six9s/Six9s. AvgFinalLoss=9e-09. (0/M fails, 0/M fails)\n",
        "#cfg.set_model_names( \"mix_d6_l3_h4_t40K_s372001\" )  # Add/SubAccuracy=Six9s/Six9s. AvgFinalLoss=5e-09. (1/M fail)\n",
        "#cfg.set_model_names( \"mix_d7_l3_h4_t50K_s372001\" )  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss=2e-08. (2/M fails, 6/M fails)\n",
        "#cfg.set_model_names( \"mix_d8_l3_h4_t60K_s173289\" )  # Add/SubAccuracy=Six9s/Five9s. AvgFinalLoss=4.7e-08. (0/M fails, 7/M fails)\n",
        "#cfg.set_model_names( \"mix_d9_l3_h4_t60K_s173289\" )  # Add/SubAccuracy=Six9s/Four9s. AvgFinalLoss=3.2e-07. (1/M fails, 33/M fails)\n",
        "#cfg.set_model_names( \"mix_d10_l3_h4_t75K_s173289\" )  # Add/SubAccuracy=Five9s/Two9s. AvgFinalLoss=1.125e-06 (2/M fail, 295/M fail)\n",
        "#cfg.set_model_names( \"mix_d10_l3_h4_t75K_gf_s173289\" )  # Add/SubAccuracy=Six9s/Three9s. GrokFast. AvgFinalLoss=8.85e-07 (1/M fail, 294/M fail). Minor accuracy improvement\n",
        "#cfg.set_model_names( \"mix_d11_l3_h4_t80K_s572091\" )  # Add/SubAccuracy=Six9s/Four9s AvgFinalLoss=3.9e-08 (0/M fail, 13/M fail)\n",
        "#cfg.set_model_names( \"mix_d12_l3_h4_t85K_s572091\" )  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss=1.7e-08. (2/M fail, 10/M fail)\n",
        "#cfg.set_model_names( \"mix_d13_l3_h4_t85K_s572091\" )  # Add/SubAccuracy=Three9s/Two9s. AvgFinalLoss=9.5e-06. (399/M fail, 4164/M fail)\n",
        "\n",
        "# Mixed models initialized with addition model. Params fine-tuned during training\n",
        "#cfg.set_model_names( \"ins1_mix_d5_l2_h3_t40K_s572091\" )  # Add/SubAccuracy=TODO\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l2_h3_t40K_s572091\" )  # Add/SubAccuracy=Six9s/Five9s. AvgLoss = 2.4e-08 (5/M fails)\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l3_h3_t40K_s572091\" )  # Add/SubAccuracy=Six9s/Five9s. AvgFinalLoss=1.8e-08. (3/M fails)\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l3_h3_t80K_s572091\" )  # Add/SubAccuracy=Six9s/Five9s AvgLoss = 1.6e-08 (3/M fails)\n",
        "cfg.set_model_names( \"ins1_mix_d6_l3_h4_t40K_s372001\" )  # Add/SubAccuracy=Six9s/Six9s. AvgFinalLoss=8e-09. MAIN FOCUS\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l3_h4_t40K_s173289\" )  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss=1.4e-08. (3/M fails, 2/M fails)\n",
        "#cfg.set_model_names( \"ins1_mix_d6_l3_h4_t50K_s572091\" )  # Add/SubAccuracy=Six9s/Five9s. AvgFinalLoss=2.9e-08. (4/M fails)\n",
        "#cfg.set_model_names( \"ins1_mix_d7_l3_h4_t50K_s572091\" )  # Add/SubAccuracy=Five9s/Six9s. AvgFinalLoss=1.3e-08. (4/M fails, 1/M fails)\n",
        "#cfg.set_model_names( \"ins1_mix_d8_l3_h4_t70K_s572091\" )  # Add/SubAccuracy=Four9s/Two9s. AvgFinalLoss=7.2e-06. (50/M fails, 1196/M fails)\n",
        "#cfg.set_model_names( \"ins1_mix_d9_l3_h4_t70K_s572091\" )  # Add/SubAccuracy=TODO. AvgFinalLoss=TODO. (50/M fails, TODO/M fails)\n",
        "#cfg.set_model_names( \"ins1_mix_d10_l3_h3_t50K_s572091\" )  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss 6.3e-07 (6/M fails, 7/M fails)\n",
        "#cfg.set_model_names( \"ins1_mix_d10_l3_h3_t50K_gf_s572091\" ) # Add/SubAccuracy=Five9s/Two9s. GrokFast. AvgFinalLoss=4.0e-06 (2/M fails, 1196/M fails). Worse accuracy than without GF!\n",
        "#cfg.set_model_names( \"ins1_mix_d11_l3_h4_t75K_s572091\" )  # Add/SubAccuracy=TODO. AvgFinalLoss=TODO. (TODO/M fails, TODO/M fails)\n",
        "\n",
        "# Mixed model initialized with addition model. Reset useful heads every 100 epochs during training\n",
        "#cfg.set_model_names( \"ins2_mix_d6_l4_h4_t40K_s372001\" )  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss=1.7e-08. (3/M fails, 8/M fails)\n",
        "\n",
        "# Mixed model initialized with addition model. Reset useful heads & MLPs every 100 epochs during training\n",
        "#cfg.set_model_names( \"ins3_mix_d6_l4_h3_t40K_s372001\" )  # Add/SubAccuracy=Four9s/Two9s. AvgFinalLoss=3.0e-04. (17/M fails, 3120/M fails)\n",
        "\n",
        "# Mixed model initialized with addition model. Reset useful heads & MLPs every training epoch\n",
        "#cfg.set_model_names( \"ins4_mix_d6_l4_h3_t40K_s372001\" )  # AvgFinalLoss=4.7e-06"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_IIpX2H2tNe"
      },
      "source": [
        "# Part 1B: Configuration: Input and Output file names\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5BiELcf53ms"
      },
      "outputs": [],
      "source": [
        "cfg.batch_size = 512 # Default analysis batch size\n",
        "if cfg.n_layers >= 3 and cfg.n_heads >= 4:\n",
        "  cfg.batch_size = 256 # Reduce batch size to avoid memory constraint issues.\n",
        "\n",
        "cfg.set_seed(cfg.analysis_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0DJkn5l2gq3"
      },
      "outputs": [],
      "source": [
        "base_repo_name = 'PhilipQuirke'\n",
        "model_pth_fname = 'model.pth'\n",
        "model_training_loss_fname = 'training_loss.json'\n",
        "model_sae_pth_fname = 'model_sae.pth'\n",
        "\n",
        "cfg.hf_repo = base_repo_name + \"/QuantaMaths_\" + cfg.model_name\n",
        "\n",
        "print('Model files will be read from HuggingFace repo:', base_repo_name, model_pth_fname, 'and', model_training_loss_fname)\n",
        "print('Saving sae model to temporary Colab file:', model_sae_pth_fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfdCBTuqh4zq"
      },
      "outputs": [],
      "source": [
        "# Update \"cfg\" with additional training config (including cfg.insert_*) information from existing file:\n",
        "#      https://huggingface.co/PhilipQuirke/QuantaMaths_ins1_mix_d6_l3_h4_t40K_s372001/training_loss.json\"\n",
        "training_data_json = qmi.download_huggingface_json(cfg.hf_repo, model_training_loss_fname)\n",
        "training_loss_list = qmi.load_training_json(cfg, training_data_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI4vY-vSxvxC"
      },
      "outputs": [],
      "source": [
        "def print_config():\n",
        "  print(\"%Add=\", cfg.perc_add, \"%Sub=\", cfg.perc_sub, \"%Mult=\", cfg.perc_mult, \"InsertMode=\", cfg.insert_mode, \"File=\", cfg.model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f48_G6wr730Q"
      },
      "outputs": [],
      "source": [
        "print_config()\n",
        "print(\"weight_decay=\", cfg.weight_decay, \"lr=\", cfg.lr, \"batch_size=\", cfg.batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8RfHXneJw6n"
      },
      "source": [
        "# Part 3A: Set Up: Vocabulary / Embedding / Unembedding\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeObQk2kzAv7"
      },
      "outputs": [],
      "source": [
        "cfg.initialize_maths_token_positions()\n",
        "mmi.set_maths_vocabulary(cfg)\n",
        "mmi.set_maths_question_meanings(cfg)\n",
        "print(cfg.token_position_meanings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz6rUaYvjOcE"
      },
      "source": [
        "# Part 3B: Set Up: Create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA16Nb2PJ7MB"
      },
      "outputs": [],
      "source": [
        "# Structure is documented at https://neelnanda-io.github.io/TransformerLens/transformer_lens.html#transformer_lens.HookedTransformerConfig.HookedTransformerConfig\n",
        "ht_cfg = cfg.get_HookedTransformerConfig()\n",
        "\n",
        "# Create the main transformer model\n",
        "cfg.main_model = HookedTransformer(ht_cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KJhCxFtNKfm"
      },
      "source": [
        "# Part 5: Set Up: Load Model from HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRMkB_8GNRc0"
      },
      "outputs": [],
      "source": [
        "print(\"Loading model from HuggingFace:\", cfg.hf_repo, model_pth_fname)\n",
        "\n",
        "cfg.main_model.load_state_dict(download_file_from_hf(repo_name=cfg.hf_repo, file_name=model_pth_fname, force_is_torch=True))\n",
        "cfg.main_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5yD0orfGx4B"
      },
      "source": [
        "# Part 6: Train a SAE\n",
        "\n",
        "Train an SAE which preferably has:\n",
        "- Low Loss and MSE (good reconstruction. Very important)\n",
        "- Low sparsity (Sparsity = # neurons activating. So low sparsity means few neurons are active in any given prediction)\n",
        "- Low number of Active Neurons (makes interpretation easier)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjyzeiiSG06A"
      },
      "outputs": [],
      "source": [
        "dataloader = mmi.get_mixed_maths_dataloader(cfg, num_batches=1000, enrich_data=True)\n",
        "print(\"Data set size\", len(dataloader.dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xk4_HqhrvYGu"
      },
      "outputs": [],
      "source": [
        "sae, score, loss, sparsity, neurons_used = mmi.analyze_mlp_with_sae(cfg, dataloader, layer_num=0, encoding_dim=32, learning_rate=5e-4, sparsity_target=0.1, sparsity_weight=1e-3, num_epochs=10)\n",
        "print( f\"Score: {score:.4f}, Loss {loss:.4f}, Sparsity {sparsity:.4f}, Neurons Used: {neurons_used}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPUgY4xd5QNW"
      },
      "outputs": [],
      "source": [
        "sae, score, loss, sparsity, neurons_used = mmi.analyze_mlp_with_sae(cfg, dataloader, layer_num=0, encoding_dim=64, learning_rate=0.001, sparsity_target=0.05, sparsity_weight=0.1, num_epochs=10)\n",
        "print( f\"Score: {score:.4f}, Loss {loss:.4f}, Sparsity {sparsity:.4f}, Neurons Used: {neurons_used}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOO1Nb2lqT3D"
      },
      "source": [
        "# Part 7: Sweep hyperparams to find the best SAE\n",
        "\n",
        "Sweep hyperparameters to train/score multiple SAEs to find the best scoring SAE. Slow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Szo94L-CqUEM"
      },
      "outputs": [],
      "source": [
        "sae, score, neurons_used, params = mmi.optimize_sae_hyperparameters(cfg, dataloader, layer_num=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS_zUfwrXl6P"
      },
      "source": [
        "# Part 7: Visualize the SAE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6Kt5XD-XU9t"
      },
      "outputs": [],
      "source": [
        "mmi.analyze_and_visualize_sae(cfg, sae, dataloader, layer_num=0, max_samples=1000, perplexity=30, n_iter=250)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uG2gZSoSJD5C",
        "pTd3nmsMJV5T",
        "-KJhCxFtNKfm"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
